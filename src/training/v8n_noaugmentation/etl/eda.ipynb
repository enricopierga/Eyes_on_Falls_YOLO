{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aac31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essenziali\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf725e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install opencv-python matplotlib pandas numpy pillow scikit-learn seaborn tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc40ddd",
   "metadata": {},
   "source": [
    "# ANALISI ESPLORATIVA DEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706be0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataset_structure(dataset_path):\n",
    "    \"\"\"Esplora la struttura del dataset e conta i file.\"\"\"\n",
    "    print(\"Struttura del dataset:\")\n",
    "    total_images = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        level = root.replace(dataset_path, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f'{indent}üìÅ {os.path.basename(root)}/')\n",
    "        \n",
    "        # Conta file per tipo\n",
    "        image_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        txt_files = [f for f in files if f.lower().endswith('.txt')]\n",
    "        weight_files = [f for f in files if f.lower().endswith('.weights')]\n",
    "        \n",
    "        sub_indent = ' ' * 2 * (level + 1)\n",
    "        if image_files:\n",
    "            print(f'{sub_indent}üì∏ Immagini: {len(image_files)}')\n",
    "            total_images += len(image_files)\n",
    "        if txt_files:\n",
    "            print(f'{sub_indent}üìù File testo: {len(txt_files)}')\n",
    "        if weight_files:\n",
    "            print(f'{sub_indent}üèãÔ∏è Pesi YOLO: {len(weight_files)}')\n",
    "    \n",
    "    print(f'\\nüìä Totale immagini trovate: {total_images}')\n",
    "    return total_images\n",
    "\n",
    "# Uso\n",
    "total_imgs = explore_dataset_structure('/Users/andreavisi/Desktop/PYTHON/Sistemi operativi Dedicati 2025/PROGETTO/Eyes_on_falls_YOLO/Datasets/E-FPDS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizza_dataset(base_path=\"E-FPDS\", formato=\"custom\", classi_yolo=None):\n",
    "    \"\"\"Analizza statistiche base del dataset con gestione errori\n",
    "    \n",
    "    Args:\n",
    "        base_path (str): Percorso base del dataset\n",
    "        formato (str): 'custom' per il formato originale o 'yolo' per il formato YOLO\n",
    "        classi_yolo (dict, optional): Dizionario che mappa gli indici delle classi YOLO \n",
    "                                     ai nomi, es. {0: 'caduta', 1: 'non_caduta'}\n",
    "                                     \n",
    "    Returns:\n",
    "        tuple: (dati, bboxes, distribuzione_bbox) con statistiche del dataset\n",
    "    \"\"\"\n",
    "    print(f\"Analisi dataset: {base_path} (formato: {formato})\")\n",
    "    \n",
    "    # Valori predefiniti per classi YOLO se non specificate\n",
    "    if formato == \"yolo\" and classi_yolo is None:\n",
    "        classi_yolo = {0: 'caduta', 1: 'non_caduta'}\n",
    "        print(f\"Usando mappature classi YOLO predefinite: {classi_yolo}\")\n",
    "    \n",
    "    # Mappatura split per formato custom\n",
    "    mappatura = {\n",
    "        'train': ['split1', 'split2', 'split3', 'split10', 'split11'],\n",
    "        'test': ['split4', 'split5', 'split6', 'split7', 'split8'],\n",
    "        'valid': ['split12', 'split13']\n",
    "    }\n",
    "    \n",
    "    # Contatori\n",
    "    dati = {\n",
    "        'train': {'immagini': 0, 'cadute': 0, 'non_cadute': 0, 'immagini_con_cadute': 0, 'immagini_con_non_cadute': 0},\n",
    "        'test': {'immagini': 0, 'cadute': 0, 'non_cadute': 0, 'immagini_con_cadute': 0, 'immagini_con_non_cadute': 0},\n",
    "        'valid': {'immagini': 0, 'cadute': 0, 'non_cadute': 0, 'immagini_con_cadute': 0, 'immagini_con_non_cadute': 0},\n",
    "        'val': {'immagini': 0, 'cadute': 0, 'non_cadute': 0, 'immagini_con_cadute': 0, 'immagini_con_non_cadute': 0}  # Aggiungi 'val' per supportare entrambe le convenzioni\n",
    "    }\n",
    "    \n",
    "    # Statistiche bounding box\n",
    "    bboxes = {'larghezza': [], 'altezza': [], 'area': []}\n",
    "    \n",
    "    # Inizializza distribuzione_bbox per entrambi i formati\n",
    "    distribuzione_bbox = {\n",
    "        'total': [],  # Numero totale di bounding box per immagine\n",
    "        'fallen': [],  # Numero di bounding box 'caduta' per immagine\n",
    "        'not_fallen': [],  # Numero di bounding box 'non-caduta' per immagine\n",
    "        'set_info': {}  # Dizionario per tracciare il set di appartenenza di ogni immagine\n",
    "    }\n",
    "    \n",
    "    # Verifica esistenza del percorso base\n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"ERRORE: Il percorso base {base_path} non esiste!\")\n",
    "        return dati, bboxes, distribuzione_bbox\n",
    "    \n",
    "    # CASO 1: Formato personalizzato originale\n",
    "    if formato == \"custom\":\n",
    "        # Analizza ogni set\n",
    "        for set_nome, splits in mappatura.items():\n",
    "            for split in splits:\n",
    "                percorso = os.path.join(base_path, set_nome, split)\n",
    "                \n",
    "                if not os.path.exists(percorso):\n",
    "                    print(f\"Split non trovato: {percorso}\")\n",
    "                    continue\n",
    "                \n",
    "                # Trova file txt\n",
    "                try:\n",
    "                    files_txt = [f for f in os.listdir(percorso) if f.endswith('.txt')]\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore lettura directory {percorso}: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                for file_txt in files_txt:\n",
    "                    file_img = file_txt.replace('.txt', '.png')\n",
    "                    percorso_img = os.path.join(percorso, file_img)\n",
    "                    \n",
    "                    if os.path.exists(percorso_img):\n",
    "                        dati[set_nome]['immagini'] += 1\n",
    "                        \n",
    "                        # Leggi annotazioni\n",
    "                        try:\n",
    "                            percorso_txt = os.path.join(percorso, file_txt)\n",
    "                            \n",
    "                            # Contatori per questa immagine specifica\n",
    "                            cadute_in_immagine = False\n",
    "                            non_cadute_in_immagine = False\n",
    "                            cadute_count = 0\n",
    "                            non_cadute_count = 0\n",
    "                            \n",
    "                            with open(percorso_txt, 'r') as f:\n",
    "                                linee = f.readlines()\n",
    "                                \n",
    "                                for linea in linee:\n",
    "                                    parti = linea.strip().split()\n",
    "                                    if len(parti) >= 5:\n",
    "                                        try:\n",
    "                                            classe = int(parti[0])\n",
    "                                            left = int(parti[1])\n",
    "                                            right = int(parti[2])\n",
    "                                            top = int(parti[3])\n",
    "                                            bottom = int(parti[4])\n",
    "                                            \n",
    "                                            # Calcoli dimensioni\n",
    "                                            try:\n",
    "                                                larghezza = right - left\n",
    "                                                altezza = bottom - top\n",
    "                                                area = int(larghezza * altezza)\n",
    "                                                \n",
    "                                                if larghezza > 0 and altezza > 0:\n",
    "                                                    bboxes['larghezza'].append(larghezza)\n",
    "                                                    bboxes['altezza'].append(altezza)\n",
    "                                                    bboxes['area'].append(area)\n",
    "                                            except Exception as e:\n",
    "                                                pass  # Ignora errori di calcolo\n",
    "                                            \n",
    "                                            # Conteggi per classe\n",
    "                                            if classe == 1:\n",
    "                                                dati[set_nome]['cadute'] += 1\n",
    "                                                cadute_in_immagine = True\n",
    "                                                cadute_count += 1\n",
    "                                            elif classe == -1:\n",
    "                                                dati[set_nome]['non_cadute'] += 1\n",
    "                                                non_cadute_in_immagine = True\n",
    "                                                non_cadute_count += 1\n",
    "                                        except ValueError:\n",
    "                                            # Ignora linee con valori non interi\n",
    "                                            continue\n",
    "                            \n",
    "                            # Aggiorna contatori di immagini per categoria\n",
    "                            if cadute_in_immagine:\n",
    "                                dati[set_nome]['immagini_con_cadute'] += 1\n",
    "                            if non_cadute_in_immagine:\n",
    "                                dati[set_nome]['immagini_con_non_cadute'] += 1\n",
    "                                \n",
    "                            # Aggiungi alla distribuzione\n",
    "                            total_bbox = cadute_count + non_cadute_count\n",
    "                            distribuzione_bbox['total'].append(total_bbox)\n",
    "                            distribuzione_bbox['fallen'].append(cadute_count)\n",
    "                            distribuzione_bbox['not_fallen'].append(non_cadute_count)\n",
    "                            \n",
    "                            # Traccia il set di appartenenza\n",
    "                            idx = len(distribuzione_bbox['total']) - 1\n",
    "                            distribuzione_bbox['set_info'][idx] = set_nome\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            print(f\"Errore lettura {file_txt}: {e}\")\n",
    "    \n",
    "    # CASO 2: Formato YOLO standard\n",
    "    elif formato == \"yolo\":\n",
    "        # Nel formato YOLO, la struttura tipica √®:\n",
    "        # - images/train, images/valid (o val), images/test (cartelle immagini)\n",
    "        # - labels/train, labels/valid (o val), labels/test (cartelle annotazioni)\n",
    "        \n",
    "        # Set di dati da cercare\n",
    "        yolo_sets = ['train', 'test', 'valid', 'val']\n",
    "        \n",
    "        for set_nome in yolo_sets:\n",
    "            # Percorsi per immagini e annotazioni\n",
    "            img_dir = os.path.join(base_path, 'images', set_nome)\n",
    "            label_dir = os.path.join(base_path, 'labels', set_nome)\n",
    "            \n",
    "            if not os.path.exists(img_dir) or not os.path.exists(label_dir):\n",
    "                print(f\"Directory non trovata per set {set_nome}: {img_dir} o {label_dir}\")\n",
    "                continue\n",
    "            \n",
    "            # Estensioni immagine supportate\n",
    "            img_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
    "            img_files = []\n",
    "            for ext in img_extensions:\n",
    "                img_files.extend(glob.glob(os.path.join(img_dir, ext)))\n",
    "            \n",
    "            # Conteggio immagini\n",
    "            dati[set_nome]['immagini'] = len(img_files)\n",
    "            \n",
    "            # Trova tutti i file txt nelle cartelle labels\n",
    "            label_files = glob.glob(os.path.join(label_dir, '*.txt'))\n",
    "            \n",
    "            for label_file in label_files:\n",
    "                try:\n",
    "                    with open(label_file, 'r') as f:\n",
    "                        linee = f.readlines()\n",
    "                        \n",
    "                        # Ottieni dimensioni immagine corrispondente\n",
    "                        nome_base = os.path.basename(label_file).replace('.txt', '')\n",
    "                        img_trovata = False\n",
    "                        \n",
    "                        # Cerca il file immagine corrispondente\n",
    "                        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                            img_path = os.path.join(img_dir, nome_base + ext)\n",
    "                            if os.path.exists(img_path):\n",
    "                                img_trovata = True\n",
    "                                try:\n",
    "                                    img = Image.open(img_path)\n",
    "                                    img_width, img_height = img.size\n",
    "                                    break\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Errore apertura immagine {img_path}: {e}\")\n",
    "                                    img_width, img_height = 1, 1  # Valori predefiniti\n",
    "                        \n",
    "                        if not img_trovata:\n",
    "                            # Se non trova l'immagine, usa valori predefiniti\n",
    "                            img_width, img_height = 1, 1\n",
    "                        \n",
    "                        # Contatori per questa immagine specifica\n",
    "                        cadute_in_questa_immagine = 0\n",
    "                        non_cadute_in_questa_immagine = 0\n",
    "                        \n",
    "                        for linea in linee:\n",
    "                            parti = linea.strip().split()\n",
    "                            if len(parti) >= 5:\n",
    "                                try:\n",
    "                                    # Formato YOLO: classe x_center y_center width height (normalizzati)\n",
    "                                    classe = int(parti[0])\n",
    "                                    x_center = float(parti[1]) * img_width\n",
    "                                    y_center = float(parti[2]) * img_height\n",
    "                                    width = float(parti[3]) * img_width\n",
    "                                    height = float(parti[4]) * img_height\n",
    "                                    \n",
    "                                    # Calcola coordinate assolute\n",
    "                                    x1 = int(x_center - width/2)\n",
    "                                    y1 = int(y_center - height/2)\n",
    "                                    x2 = int(x_center + width/2)\n",
    "                                    y2 = int(y_center + height/2)\n",
    "                                    \n",
    "                                    # Calcoli dimensioni\n",
    "                                    larghezza = int(width)\n",
    "                                    altezza = int(height)\n",
    "                                    area = int(larghezza * altezza)\n",
    "                                    \n",
    "                                    if larghezza > 0 and altezza > 0:\n",
    "                                        bboxes['larghezza'].append(larghezza)\n",
    "                                        bboxes['altezza'].append(altezza)\n",
    "                                        bboxes['area'].append(area)\n",
    "                                    \n",
    "                                    # Conteggi per classe\n",
    "                                    if classe in classi_yolo:\n",
    "                                        if classi_yolo[classe].lower() == 'caduta':\n",
    "                                            dati[set_nome]['cadute'] += 1\n",
    "                                            cadute_in_questa_immagine += 1\n",
    "                                        else:\n",
    "                                            dati[set_nome]['non_cadute'] += 1\n",
    "                                            non_cadute_in_questa_immagine += 1\n",
    "                                except (ValueError, IndexError) as e:\n",
    "                                    print(f\"Errore parsing linea in {label_file}: {e}\")\n",
    "                                    continue\n",
    "                        \n",
    "                        # Aggiorna contatori di immagini per categoria\n",
    "                        if cadute_in_questa_immagine > 0:\n",
    "                            dati[set_nome]['immagini_con_cadute'] += 1\n",
    "                        if non_cadute_in_questa_immagine > 0:\n",
    "                            dati[set_nome]['immagini_con_non_cadute'] += 1\n",
    "                        \n",
    "                        # Aggiungi alla distribuzione\n",
    "                        total_bbox = cadute_in_questa_immagine + non_cadute_in_questa_immagine\n",
    "                        distribuzione_bbox['total'].append(total_bbox)\n",
    "                        distribuzione_bbox['fallen'].append(cadute_in_questa_immagine)\n",
    "                        distribuzione_bbox['not_fallen'].append(non_cadute_in_questa_immagine)\n",
    "                        \n",
    "                        # Traccia il set di appartenenza\n",
    "                        idx = len(distribuzione_bbox['total']) - 1\n",
    "                        distribuzione_bbox['set_info'][idx] = set_nome\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore lettura {label_file}: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"ERRORE: Formato '{formato}' non supportato! Usa 'custom' o 'yolo'.\")\n",
    "        return dati, bboxes, distribuzione_bbox\n",
    "    \n",
    "    # Stampa risultati\n",
    "    print(\"\\n--- STATISTICHE DATASET ---\")\n",
    "    \n",
    "    # Consideriamo solo i set con dati per le statistiche\n",
    "    set_con_dati = [s for s in dati.keys() if dati[s]['immagini'] > 0]\n",
    "    \n",
    "    print(f\"Immagini totali: {sum(dati[s]['immagini'] for s in set_con_dati)}\")\n",
    "    \n",
    "    # Statistiche annotazioni\n",
    "    totale_annotazioni = sum(dati[s]['cadute'] + dati[s]['non_cadute'] for s in set_con_dati)\n",
    "    print(f\"Annotazioni totali: {totale_annotazioni}\")\n",
    "    \n",
    "    if totale_annotazioni > 0:\n",
    "        totale_cadute = sum(dati[s]['cadute'] for s in set_con_dati)\n",
    "        totale_non_cadute = sum(dati[s]['non_cadute'] for s in set_con_dati)\n",
    "        print(f\"Annotazioni di cadute: {totale_cadute} ({totale_cadute/totale_annotazioni*100:.1f}%)\")\n",
    "        print(f\"Annotazioni di non-cadute: {totale_non_cadute} ({totale_non_cadute/totale_annotazioni*100:.1f}%)\")\n",
    "    \n",
    "    # Statistiche immagini per categoria\n",
    "    totale_immagini_con_cadute = sum(dati[s]['immagini_con_cadute'] for s in set_con_dati)\n",
    "    totale_immagini_con_non_cadute = sum(dati[s]['immagini_con_non_cadute'] for s in set_con_dati)\n",
    "    totale_immagini = sum(dati[s]['immagini'] for s in set_con_dati)\n",
    "    \n",
    "    print(f\"\\nImmagini con cadute: {totale_immagini_con_cadute} ({totale_immagini_con_cadute/totale_immagini*100:.1f}%)\")\n",
    "    print(f\"Immagini con non-cadute: {totale_immagini_con_non_cadute} ({totale_immagini_con_non_cadute/totale_immagini*100:.1f}%)\")\n",
    "    \n",
    "    # Nota: alcune immagini potrebbero contenere entrambe le categorie, quindi la somma potrebbe non essere 100%\n",
    "    immagini_con_entrambe = totale_immagini - (totale_immagini_con_cadute + totale_immagini_con_non_cadute - sum(min(dati[s]['immagini_con_cadute'], dati[s]['immagini_con_non_cadute']) for s in set_con_dati))\n",
    "    if immagini_con_entrambe != 0:\n",
    "        print(f\"Immagini con entrambe le categorie: {immagini_con_entrambe}\")\n",
    "    \n",
    "    # Statistiche per set\n",
    "    print(\"\\n--- STATISTICHE PER SET ---\")\n",
    "    for set_nome in set_con_dati:\n",
    "        stat = dati[set_nome]\n",
    "        tot_ann = stat['cadute'] + stat['non_cadute']\n",
    "        print(f\"\\n{set_nome.upper()}:\")\n",
    "        print(f\"  Immagini: {stat['immagini']}\")\n",
    "        print(f\"  Annotazioni totali: {tot_ann}\")\n",
    "        if tot_ann > 0:\n",
    "            print(f\"  Annotazioni di cadute: {stat['cadute']} ({stat['cadute']/tot_ann*100:.1f}%)\")\n",
    "            print(f\"  Annotazioni di non-cadute: {stat['non_cadute']} ({stat['non_cadute']/tot_ann*100:.1f}%)\")\n",
    "        \n",
    "        print(f\"  Immagini con cadute: {stat['immagini_con_cadute']} ({stat['immagini_con_cadute']/stat['immagini']*100:.1f}%)\")\n",
    "        print(f\"  Immagini con non-cadute: {stat['immagini_con_non_cadute']} ({stat['immagini_con_non_cadute']/stat['immagini']*100:.1f}%)\")\n",
    "    \n",
    "    return dati, bboxes, distribuzione_bbox\n",
    "\n",
    "def visualizza_statistiche(dati, bboxes, distribuzione_bbox=None):\n",
    "    \"\"\"Versione ampliata che visualizza statistiche del dataset\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Controlla che ci siano dati\n",
    "    # Includi solo i set che hanno dati\n",
    "    sets = [s for s in dati.keys() if dati[s]['immagini'] > 0]\n",
    "    \n",
    "    if not sets:\n",
    "        print(\"Nessun set con dati trovato\")\n",
    "        return\n",
    "    \n",
    "    # Gestione del caso in cui distribuzione_bbox √® None\n",
    "    if distribuzione_bbox is None:\n",
    "        distribuzione_bbox = {'total': [], 'fallen': [], 'not_fallen': []}\n",
    "    \n",
    "    # Prepara i dati per i grafici (annotazioni)\n",
    "    cadute = [dati[s]['cadute'] for s in sets]\n",
    "    non_cadute = [dati[s]['non_cadute'] for s in sets]\n",
    "    \n",
    "    # Prepara i dati per i grafici (immagini per categoria)\n",
    "    img_con_cadute = [dati[s]['immagini_con_cadute'] for s in sets]\n",
    "    img_con_non_cadute = [dati[s]['immagini_con_non_cadute'] for s in sets]\n",
    "    \n",
    "    if sum(cadute) == 0 and sum(non_cadute) == 0:\n",
    "        print(\"Nessun dato da visualizzare\")\n",
    "        return\n",
    "    \n",
    "    # Assicuriamoci che i dati siano tutti in formato numpy array corretto per evitare problemi con matplotlib\n",
    "    # Converti esplicitamente in array numpy con dtype=float per evitare problemi con il plotting\n",
    "    if bboxes['larghezza'] and bboxes['altezza'] and bboxes['area']:\n",
    "        bboxes['larghezza'] = np.array(bboxes['larghezza'], dtype=float)\n",
    "        bboxes['altezza'] = np.array(bboxes['altezza'], dtype=float)\n",
    "        bboxes['area'] = np.array(bboxes['area'], dtype=float)\n",
    "    \n",
    "    # Determina se mostrare la distribuzione del numero di bbox\n",
    "    ha_distribuzione = distribuzione_bbox is not None and len(distribuzione_bbox.get('total', [])) > 0\n",
    "    \n",
    "    # Se abbiamo distribuzione, convertiamola in array numpy\n",
    "    if ha_distribuzione:\n",
    "        distribuzione_bbox['total'] = np.array(distribuzione_bbox['total'], dtype=int)\n",
    "        distribuzione_bbox['fallen'] = np.array(distribuzione_bbox['fallen'], dtype=int)\n",
    "        distribuzione_bbox['not_fallen'] = np.array(distribuzione_bbox['not_fallen'], dtype=int)\n",
    "    \n",
    "    # Calcola dimensione figura in base ai grafici da mostrare\n",
    "    n_rows = 4 if ha_distribuzione else 3\n",
    "    plt.figure(figsize=(18, n_rows * 5))\n",
    "    \n",
    "    # 1. Grafico barre - distribuzione ANNOTAZIONI per set\n",
    "    plt.subplot(n_rows, 2, 1)\n",
    "    x = np.arange(len(sets))\n",
    "    larghezza = 0.35\n",
    "    \n",
    "    plt.bar(x - larghezza/2, cadute, larghezza, label='Cadute', color='red')\n",
    "    plt.bar(x + larghezza/2, non_cadute, larghezza, label='Non-cadute', color='green')\n",
    "    \n",
    "    plt.xlabel('Set')\n",
    "    plt.ylabel('Numero annotazioni')\n",
    "    plt.title('Distribuzione ANNOTAZIONI per Set')\n",
    "    plt.xticks(x, [s.capitalize() for s in sets])\n",
    "    plt.legend()\n",
    "    \n",
    "    # 2. Grafico a torta - distribuzione totale ANNOTAZIONI\n",
    "    plt.subplot(n_rows, 2, 2)\n",
    "    totale_cadute = sum(cadute)\n",
    "    totale_non_cadute = sum(non_cadute)\n",
    "    \n",
    "    if totale_cadute > 0 or totale_non_cadute > 0:\n",
    "        plt.pie([totale_cadute, totale_non_cadute], \n",
    "                labels=[f'Cadute ({totale_cadute})', f'Non-cadute ({totale_non_cadute})'],\n",
    "                colors=['red', 'green'],\n",
    "                autopct='%1.1f%%')\n",
    "        plt.title('Distribuzione Totale ANNOTAZIONI')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Nessun dato disponibile', ha='center')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # 3. Grafico barre - distribuzione IMMAGINI per set\n",
    "    plt.subplot(n_rows, 2, 3)\n",
    "    \n",
    "    plt.bar(x - larghezza/2, img_con_cadute, larghezza, label='Immagini con cadute', color='tomato')\n",
    "    plt.bar(x + larghezza/2, img_con_non_cadute, larghezza, label='Immagini con non-cadute', color='lightgreen')\n",
    "    \n",
    "    plt.xlabel('Set')\n",
    "    plt.ylabel('Numero immagini')\n",
    "    plt.title('Distribuzione IMMAGINI per Categoria e Set')\n",
    "    plt.xticks(x, [s.capitalize() for s in sets])\n",
    "    plt.legend()\n",
    "    \n",
    "    # 4. Grafico a torta - distribuzione totale IMMAGINI\n",
    "    plt.subplot(n_rows, 2, 4)\n",
    "    tot_img_cadute = sum(img_con_cadute)\n",
    "    tot_img_non_cadute = sum(img_con_non_cadute)\n",
    "    \n",
    "    if tot_img_cadute > 0 or tot_img_non_cadute > 0:\n",
    "        plt.pie([tot_img_cadute, tot_img_non_cadute], \n",
    "                labels=[f'Immagini con cadute ({tot_img_cadute})', \n",
    "                       f'Immagini con non-cadute ({tot_img_non_cadute})'],\n",
    "                colors=['tomato', 'lightgreen'],\n",
    "                autopct='%1.1f%%')\n",
    "        plt.title('Distribuzione Totale IMMAGINI per Categoria')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Nessun dato disponibile', ha='center')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # 5-6. Distribuzione del numero di bounding box per immagine\n",
    "    if ha_distribuzione and len(distribuzione_bbox['total']) > 0:\n",
    "        # Distribuzione del numero totale di bounding box\n",
    "        plt.subplot(n_rows, 2, 5)\n",
    "        max_val = int(np.max(distribuzione_bbox['total'])) if len(distribuzione_bbox['total']) > 0 else 0\n",
    "        bins = range(0, max_val + 2)  # +2 per assicurarsi che l'ultimo bin sia incluso\n",
    "        \n",
    "        plt.hist(distribuzione_bbox['total'], bins=bins, alpha=0.7, color='blue', \n",
    "                 align='left', rwidth=0.8)\n",
    "        \n",
    "        plt.xlabel('Numero di bbox per immagine')\n",
    "        plt.ylabel('Frequenza')\n",
    "        plt.title('Distribuzione del Numero Totale di Bounding Box per Immagine')\n",
    "        plt.xticks(range(0, max_val + 1))\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Evidenzia immagini con pi√π di 1 bbox\n",
    "        multi_bbox = np.sum(distribuzione_bbox['total'] > 1)\n",
    "        pct_multi = (multi_bbox / len(distribuzione_bbox['total'])) * 100 if len(distribuzione_bbox['total']) > 0 else 0\n",
    "        plt.annotate(f'Immagini con multipli bbox: {multi_bbox} ({pct_multi:.1f}%)', \n",
    "                     xy=(0.5, 0.9), xycoords='axes fraction', \n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", alpha=0.3),\n",
    "                     ha='center')\n",
    "        \n",
    "        # Distribuzione separata per classe\n",
    "        plt.subplot(n_rows, 2, 6)\n",
    "        max_fallen = int(np.max(distribuzione_bbox['fallen'])) if len(distribuzione_bbox['fallen']) > 0 else 0\n",
    "        max_not_fallen = int(np.max(distribuzione_bbox['not_fallen'])) if len(distribuzione_bbox['not_fallen']) > 0 else 0\n",
    "        max_class = max(max_fallen, max_not_fallen)\n",
    "        bins = range(0, max_class + 2)\n",
    "        \n",
    "        plt.hist([distribuzione_bbox['fallen'], distribuzione_bbox['not_fallen']], \n",
    "                 bins=bins, alpha=0.7, \n",
    "                 label=['Cadute', 'Non-cadute'], \n",
    "                 color=['red', 'green'], \n",
    "                 align='left', rwidth=0.8)\n",
    "        \n",
    "        plt.xlabel('Numero di bbox per immagine')\n",
    "        plt.ylabel('Frequenza')\n",
    "        plt.title('Distribuzione del Numero di Bounding Box per Classe')\n",
    "        plt.xticks(range(0, max_class + 1))\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Statistiche per immagini con pi√π bbox della stessa classe\n",
    "        multi_fallen = np.sum(distribuzione_bbox['fallen'] > 1)\n",
    "        multi_not_fallen = np.sum(distribuzione_bbox['not_fallen'] > 1)\n",
    "        \n",
    "        pct_multi_fallen = (multi_fallen / np.sum(distribuzione_bbox['fallen'] > 0)) * 100 if np.sum(distribuzione_bbox['fallen'] > 0) > 0 else 0\n",
    "        pct_multi_not_fallen = (multi_not_fallen / np.sum(distribuzione_bbox['not_fallen'] > 0)) * 100 if np.sum(distribuzione_bbox['not_fallen'] > 0) > 0 else 0\n",
    "        \n",
    "        plt.annotate(f'Immagini con multipli bbox caduta: {multi_fallen} ({pct_multi_fallen:.1f}%)\\n'\n",
    "                     f'Immagini con multipli bbox non-caduta: {multi_not_fallen} ({pct_multi_not_fallen:.1f}%)', \n",
    "                     xy=(0.5, 0.9), xycoords='axes fraction', \n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", alpha=0.3),\n",
    "                     ha='center')\n",
    "\n",
    "def mostra_esempi(base_path=\"Datasets/E-FPDS\", num_esempi=3):\n",
    "    \"\"\"Mostra esempi di immagini con annotazioni\"\"\"\n",
    "    # Mappatura split\n",
    "    mappatura = {\n",
    "        'train': ['split1', 'split2', 'split3', 'split10', 'split11'],\n",
    "        'test': ['split4', 'split5', 'split6', 'split7', 'split8'],\n",
    "        'valid': ['split12', 'split13']\n",
    "    }\n",
    "    \n",
    "    # Raccogli esempi\n",
    "    esempi_cadute = []\n",
    "    esempi_non_cadute = []\n",
    "    \n",
    "    for set_nome, splits in mappatura.items():\n",
    "        for split in splits:\n",
    "            percorso = os.path.join(base_path, set_nome, split)\n",
    "            if not os.path.exists(percorso):\n",
    "                continue\n",
    "            \n",
    "            files_txt = [f for f in os.listdir(percorso) if f.endswith('.txt')]\n",
    "            for file_txt in files_txt:\n",
    "                file_img = file_txt.replace('.txt', '.png')\n",
    "                percorso_img = os.path.join(percorso, file_img)\n",
    "                \n",
    "                if not os.path.exists(percorso_img):\n",
    "                    continue\n",
    "                \n",
    "                percorso_txt = os.path.join(percorso, file_txt)\n",
    "                try:\n",
    "                    with open(percorso_txt, 'r') as f:\n",
    "                        linee = f.readlines()\n",
    "                        for linea in linee:\n",
    "                            parti = linea.strip().split()\n",
    "                            if len(parti) >= 5:\n",
    "                                classe = int(parti[0])\n",
    "                                bbox = [int(p) for p in parti[1:5]]\n",
    "                                \n",
    "                                esempio = {\n",
    "                                    'percorso_img': percorso_img,\n",
    "                                    'set': set_nome,\n",
    "                                    'split': split,\n",
    "                                    'file': file_img,\n",
    "                                    'classe': classe,\n",
    "                                    'bbox': bbox\n",
    "                                }\n",
    "                                \n",
    "                                if classe == 1:\n",
    "                                    esempi_cadute.append(esempio)\n",
    "                                elif classe == -1:\n",
    "                                    esempi_non_cadute.append(esempio)\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    # Seleziona esempi casuali\n",
    "    random.shuffle(esempi_cadute)\n",
    "    random.shuffle(esempi_non_cadute)\n",
    "    \n",
    "    esempi_cadute = esempi_cadute[:num_esempi]\n",
    "    esempi_non_cadute = esempi_non_cadute[:num_esempi]\n",
    "    \n",
    "    # Crea visualizzazione\n",
    "    num_righe = 2\n",
    "    num_colonne = max(len(esempi_cadute), len(esempi_non_cadute))\n",
    "    \n",
    "    if num_colonne == 0:\n",
    "        print(\"Nessun esempio trovato!\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Esempi cadute\n",
    "    for i, esempio in enumerate(esempi_cadute):\n",
    "        plt.subplot(num_righe, num_colonne, i + 1)\n",
    "        \n",
    "        img = np.array(Image.open(esempio['percorso_img']))\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        left, right, top, bottom = esempio['bbox']\n",
    "        rect = patches.Rectangle((left, top), right-left, bottom-top, \n",
    "                                linewidth=2, edgecolor='r', facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        plt.title(f\"Caduta\\n{esempio['set']}/{esempio['split']}/{esempio['file']}\", fontsize=8)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # Esempi non-cadute\n",
    "    for i, esempio in enumerate(esempi_non_cadute):\n",
    "        plt.subplot(num_righe, num_colonne, num_colonne + i + 1)\n",
    "        \n",
    "        img = np.array(Image.open(esempio['percorso_img']))\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        left, right, top, bottom = esempio['bbox']\n",
    "        rect = patches.Rectangle((left, top), right-left, bottom-top, \n",
    "                                linewidth=2, edgecolor='g', facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        plt.title(f\"Non-caduta\\n{esempio['set']}/{esempio['split']}/{esempio['file']}\", fontsize=8)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e36bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi base\n",
    "dati, bboxes, distribuzione_bbox = analizza_dataset(\"/Users/andreavisi/Desktop/PYTHON/Sistemi operativi Dedicati 2025/PROGETTO/Eyes_on_falls_YOLO/Datasets/balanced_yolo_dataset\", formato=\"yolo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74752790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazioni\n",
    "visualizza_statistiche(dati, bboxes, distribuzione_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra esempi\n",
    "mostra_esempi(\"Datasets/E-FPDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\".\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d52d0",
   "metadata": {},
   "source": [
    "# 1. Preparazione del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42180fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script per verificare e modificare le annotazioni del dataset\n",
    "Obiettivo: 0 per not_fallen, 1 per fallen, nessuna label se nessun soggetto\n",
    "\"\"\"\n",
    "\n",
    "class DatasetAnnotationChecker:\n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.annotations = []\n",
    "        self.annotation_stats = Counter()\n",
    "        self.class_mapping = {}\n",
    "        \n",
    "    def scan_dataset(self):\n",
    "        \"\"\"Scansiona il dataset per trovare tutti i tipi di annotazioni\"\"\"\n",
    "        print(f\"Scansionando il dataset in: {self.dataset_path}\")\n",
    "        \n",
    "        # Cerca file di annotazioni comuni\n",
    "        annotation_files = []\n",
    "        \n",
    "        for root, dirs, files in os.walk(self.dataset_path):\n",
    "            for file in files:\n",
    "                if file.endswith(('.json', '.txt', '.csv', '.xml', '.yaml', '.yml')):\n",
    "                    annotation_files.append(os.path.join(root, file))\n",
    "        \n",
    "        print(f\"Trovati {len(annotation_files)} possibili file di annotazioni\")\n",
    "        \n",
    "        # Analizza ogni file\n",
    "        for file_path in annotation_files:\n",
    "            try:\n",
    "                if file_path.endswith('.json'):\n",
    "                    self._parse_json_annotations(file_path)\n",
    "                elif file_path.endswith('.txt'):\n",
    "                    self._parse_txt_annotations(file_path)\n",
    "                elif file_path.endswith('.csv'):\n",
    "                    self._parse_csv_annotations(file_path)\n",
    "                # Aggiungi altri formati se necessario\n",
    "            except Exception as e:\n",
    "                print(f\"Errore nel parsing di {file_path}: {e}\")\n",
    "        \n",
    "        self._analyze_annotations()\n",
    "    \n",
    "    def _parse_json_annotations(self, file_path):\n",
    "        \"\"\"Parsing file JSON\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                self._extract_labels_from_json(data, file_path)\n",
    "            except json.JSONDecodeError:\n",
    "                # Prova a leggere come JSONL (una riga per JSON)\n",
    "                f.seek(0)\n",
    "                for line_num, line in enumerate(f, 1):\n",
    "                    try:\n",
    "                        data = json.loads(line.strip())\n",
    "                        self._extract_labels_from_json(data, f\"{file_path}:line{line_num}\")\n",
    "                    except:\n",
    "                        continue\n",
    "    \n",
    "    def _extract_labels_from_json(self, data, source):\n",
    "        \"\"\"Estrae le label da strutture JSON\"\"\"\n",
    "        def extract_recursive(obj, path=\"\"):\n",
    "            if isinstance(obj, dict):\n",
    "                # Cerca chiavi comuni per le label\n",
    "                label_keys = ['label', 'class', 'category', 'annotation', 'gt', 'ground_truth', 'target']\n",
    "                for key in label_keys:\n",
    "                    if key in obj:\n",
    "                        self.annotations.append({\n",
    "                            'source': source,\n",
    "                            'path': f\"{path}.{key}\" if path else key,\n",
    "                            'value': obj[key],\n",
    "                            'type': type(obj[key]).__name__\n",
    "                        })\n",
    "                \n",
    "                # Ricerca ricorsiva\n",
    "                for k, v in obj.items():\n",
    "                    extract_recursive(v, f\"{path}.{k}\" if path else k)\n",
    "            \n",
    "            elif isinstance(obj, list):\n",
    "                for i, item in enumerate(obj):\n",
    "                    extract_recursive(item, f\"{path}[{i}]\")\n",
    "        \n",
    "        extract_recursive(data)\n",
    "    \n",
    "    def _parse_txt_annotations(self, file_path):\n",
    "        \"\"\"Parsing file TXT (formato YOLO o simili)\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    # Formato YOLO: class_id x y w h\n",
    "                    parts = line.split()\n",
    "                    if parts:\n",
    "                        try:\n",
    "                            # Primo elemento √® spesso la classe\n",
    "                            class_val = parts[0]\n",
    "                            # Prova a convertire in numero\n",
    "                            try:\n",
    "                                class_val = int(class_val)\n",
    "                            except:\n",
    "                                try:\n",
    "                                    class_val = float(class_val)\n",
    "                                except:\n",
    "                                    pass  # Mantieni come stringa\n",
    "                            \n",
    "                            self.annotations.append({\n",
    "                                'source': file_path,\n",
    "                                'path': f\"line{line_num}\",\n",
    "                                'value': class_val,\n",
    "                                'type': type(class_val).__name__,\n",
    "                                'full_line': line\n",
    "                            })\n",
    "                        except:\n",
    "                            continue\n",
    "    \n",
    "    def _parse_csv_annotations(self, file_path):\n",
    "        \"\"\"Parsing file CSV\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Cerca colonne che potrebbero contenere label\n",
    "            label_columns = []\n",
    "            for col in df.columns:\n",
    "                col_lower = col.lower()\n",
    "                if any(keyword in col_lower for keyword in ['label', 'class', 'category', 'target', 'annotation']):\n",
    "                    label_columns.append(col)\n",
    "            \n",
    "            for col in label_columns:\n",
    "                unique_values = df[col].unique()\n",
    "                for val in unique_values:\n",
    "                    if pd.notna(val):  # Ignora NaN\n",
    "                        self.annotations.append({\n",
    "                            'source': file_path,\n",
    "                            'path': col,\n",
    "                            'value': val,\n",
    "                            'type': type(val).__name__\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel parsing CSV {file_path}: {e}\")\n",
    "    \n",
    "    def _analyze_annotations(self):\n",
    "        \"\"\"Analizza le annotazioni trovate\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ANALISI DELLE ANNOTAZIONI TROVATE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if not self.annotations:\n",
    "            print(\"‚ùå Nessuna annotazione trovata!\")\n",
    "            return\n",
    "        \n",
    "        # Conta i valori unici\n",
    "        values_counter = Counter()\n",
    "        sources_counter = Counter()\n",
    "        types_counter = Counter()\n",
    "        \n",
    "        for ann in self.annotations:\n",
    "            values_counter[ann['value']] += 1\n",
    "            sources_counter[ann['source']] += 1\n",
    "            types_counter[ann['type']] += 1\n",
    "        \n",
    "        print(f\"üìä Totale annotazioni trovate: {len(self.annotations)}\")\n",
    "        print(f\"üìÅ File con annotazioni: {len(sources_counter)}\")\n",
    "        \n",
    "        print(\"\\nüî¢ VALORI DELLE LABEL TROVATI:\")\n",
    "        for value, count in values_counter.most_common():\n",
    "            print(f\"  {value} ({type(value).__name__}): {count} occorrenze\")\n",
    "        \n",
    "        print(\"\\nüìÇ DISTRIBUZIONE PER FILE:\")\n",
    "        for source, count in sources_counter.most_common():\n",
    "            filename = os.path.basename(source)\n",
    "            print(f\"  {filename}: {count} annotazioni\")\n",
    "        \n",
    "        # Analisi pattern\n",
    "        self._detect_patterns(values_counter)\n",
    "    \n",
    "    def _detect_patterns(self, values_counter):\n",
    "        \"\"\"Rileva pattern comuni nelle annotazioni\"\"\"\n",
    "        print(\"\\nüîç ANALISI PATTERN:\")\n",
    "        \n",
    "        unique_values = list(values_counter.keys())\n",
    "        \n",
    "        # Pattern numerici\n",
    "        numeric_values = []\n",
    "        string_values = []\n",
    "        \n",
    "        for val in unique_values:\n",
    "            if isinstance(val, (int, float)):\n",
    "                numeric_values.append(val)\n",
    "            else:\n",
    "                string_values.append(val)\n",
    "        \n",
    "        if numeric_values:\n",
    "            print(f\"  üìà Valori numerici: {sorted(numeric_values)}\")\n",
    "            \n",
    "            # Controlla se sono -1, 0, 1\n",
    "            if set(numeric_values) == {-1, 0, 1}:\n",
    "                print(\"  ‚úÖ Pattern rilevato: valori -1, 0, 1 (possibile: -1=nessun soggetto, 0=not_fallen, 1=fallen)\")\n",
    "            elif set(numeric_values) == {0, 1}:\n",
    "                print(\"  ‚úÖ Pattern rilevato: valori binari 0, 1\")\n",
    "            elif set(numeric_values) == {1, 2}:\n",
    "                print(\"  ‚úÖ Pattern rilevato: valori 1, 2 (possibile: 1=not_fallen, 2=fallen)\")\n",
    "        \n",
    "        if string_values:\n",
    "            print(f\"  üìù Valori stringa: {string_values}\")\n",
    "            \n",
    "            # Controlla pattern comuni\n",
    "            lower_strings = [s.lower() if isinstance(s, str) else s for s in string_values]\n",
    "            if 'fallen' in lower_strings and 'not_fallen' in lower_strings:\n",
    "                print(\"  ‚úÖ Pattern rilevato: 'fallen' e 'not_fallen'\")\n",
    "    \n",
    "    def suggest_mapping(self):\n",
    "        \"\"\"Suggerisce una mappatura per le label\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SUGGERIMENTI PER LA MAPPATURA\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        values_counter = Counter(ann['value'] for ann in self.annotations)\n",
    "        unique_values = list(values_counter.keys())\n",
    "        \n",
    "        print(\"üéØ Obiettivo: 0 per not_fallen, 1 per fallen, nessuna label per nessun soggetto\")\n",
    "        print(\"\\nüí° SUGGERIMENTI:\")\n",
    "        \n",
    "        # Suggerimenti basati sui pattern rilevati\n",
    "        if -1 in unique_values and 0 in unique_values and 1 in unique_values:\n",
    "            print(\"  üìã Mappatura suggerita per pattern (-1, 0, 1):\")\n",
    "            print(\"     -1 ‚Üí Elimina (nessun soggetto)\")\n",
    "            print(\"     0 ‚Üí 0 (not_fallen)\")\n",
    "            print(\"     1 ‚Üí 1 (fallen)\")\n",
    "        \n",
    "        elif any(isinstance(v, str) and 'fallen' in v.lower() for v in unique_values):\n",
    "            print(\"  üìã Mappatura suggerita per pattern con stringhe:\")\n",
    "            for val in unique_values:\n",
    "                if isinstance(val, str):\n",
    "                    val_lower = val.lower()\n",
    "                    if 'not_fallen' in val_lower or 'not fallen' in val_lower:\n",
    "                        print(f\"     '{val}' ‚Üí 0 (not_fallen)\")\n",
    "                    elif 'fallen' in val_lower:\n",
    "                        print(f\"     '{val}' ‚Üí 1 (fallen)\")\n",
    "        \n",
    "        # Chiedi conferma per la mappatura\n",
    "        self._interactive_mapping(unique_values)\n",
    "    \n",
    "    def _interactive_mapping(self, unique_values):\n",
    "        \"\"\"Mappatura interattiva\"\"\"\n",
    "        print(\"\\nüîß CONFIGURAZIONE MAPPATURA INTERATTIVA:\")\n",
    "        print(\"Per ogni valore, specifica la nuova label (0, 1, o 'remove' per eliminare):\")\n",
    "        \n",
    "        mapping = {}\n",
    "        for val in unique_values:\n",
    "            while True:\n",
    "                response = input(f\"  {val} ‚Üí \").strip().lower()\n",
    "                if response in ['0', '1']:\n",
    "                    mapping[val] = int(response)\n",
    "                    break\n",
    "                elif response in ['remove', 'delete', 'eliminate', '']:\n",
    "                    mapping[val] = 'remove'\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"    ‚ö†Ô∏è  Inserisci '0', '1', o 'remove'\")\n",
    "        \n",
    "        self.class_mapping = mapping\n",
    "        print(f\"\\n‚úÖ Mappatura configurata: {mapping}\")\n",
    "        \n",
    "        # Salva la mappatura\n",
    "        self._save_mapping()\n",
    "    \n",
    "    def _save_mapping(self):\n",
    "        \"\"\"Salva la mappatura in un file\"\"\"\n",
    "        mapping_file = os.path.join(self.dataset_path, 'label_mapping.json')\n",
    "        \n",
    "        mapping_data = {\n",
    "            'timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'original_target': \"0 per not_fallen, 1 per fallen, nessuna label per nessun soggetto\",\n",
    "            'mapping': self.class_mapping,\n",
    "            'source_analysis': {\n",
    "                'total_annotations': len(self.annotations),\n",
    "                'unique_values': list(set(ann['value'] for ann in self.annotations))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(mapping_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(mapping_data, f, indent=2, ensure_ascii=False, default=str)\n",
    "        \n",
    "        print(f\"üíæ Mappatura salvata in: {mapping_file}\")\n",
    "    \n",
    "    def generate_conversion_script(self):\n",
    "        \"\"\"Genera uno script per applicare la conversione\"\"\"\n",
    "        if not self.class_mapping:\n",
    "            print(\"‚ùå Nessuna mappatura configurata!\")\n",
    "            return\n",
    "        \n",
    "        script_content = f'''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script generato automaticamente per convertire le annotazioni\n",
    "Mappatura: {self.class_mapping}\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_annotations(dataset_path):\n",
    "    \"\"\"Converte le annotazioni secondo la mappatura specificata\"\"\"\n",
    "    \n",
    "    mapping = {json.dumps(self.class_mapping, default=str)}\n",
    "    \n",
    "    # Crea backup\n",
    "    backup_dir = os.path.join(dataset_path, f\"backup_{{datetime.now().strftime('%Y%m%d_%H%M%S')}}\")\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"üîÑ Creando backup in: {{backup_dir}}\")\n",
    "    \n",
    "    # Applica la conversione ai file trovati\n",
    "    # [Qui inseriresti la logica specifica per il tuo formato di annotazioni]\n",
    "    \n",
    "    print(\"‚úÖ Conversione completata!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = input(\"Inserisci il path del dataset: \").strip()\n",
    "    convert_annotations(dataset_path)\n",
    "'''\n",
    "        \n",
    "        script_file = os.path.join(self.dataset_path, 'convert_annotations.py')\n",
    "        with open(script_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(script_content)\n",
    "        \n",
    "        print(f\"üîß Script di conversione generato: {script_file}\")\n",
    "\n",
    "checker = DatasetAnnotationChecker('/Users/andreavisi/Desktop/PYTHON/Sistemi operativi Dedicati 2025/PROGETTO/Eyes_on_falls_YOLO/Datasets/balanced_yolo_dataset')\n",
    "\n",
    "checker.scan_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412bdd6b",
   "metadata": {},
   "source": [
    "## Conversione dei label in formato YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converti_annotazioni_yolo(base_path=\"E-FPDS\", output_path=\"yolo_dataset\"):\n",
    "    \"\"\"Converte le annotazioni dal formato E-FPDS al formato YOLO, supportando sia 'valid' che 'val'.\"\"\"\n",
    "    \n",
    "    # Crea struttura cartelle\n",
    "    os.makedirs(f\"{output_path}/images/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{output_path}/images/val\", exist_ok=True)   # Sempre 'val' nella destinazione\n",
    "    os.makedirs(f\"{output_path}/images/test\", exist_ok=True)\n",
    "    os.makedirs(f\"{output_path}/labels/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{output_path}/labels/val\", exist_ok=True)   # Sempre 'val' nella destinazione\n",
    "    os.makedirs(f\"{output_path}/labels/test\", exist_ok=True)\n",
    "    \n",
    "    # Mappatura split - gestisce sia 'valid' che 'val' come fonte\n",
    "    mappatura = {\n",
    "        'train': ['split1', 'split2', 'split3', 'split10', 'split11'],\n",
    "        'test': ['split4', 'split5', 'split6', 'split7', 'split8'],\n",
    "    }\n",
    "    \n",
    "    # Verifica se esiste 'valid' o 'val' e aggiorna la mappatura\n",
    "    if os.path.exists(os.path.join(base_path, \"valid\")):\n",
    "        mappatura['valid'] = ['split12', 'split13']  # Usa 'valid' come chiave se esiste la cartella\n",
    "        validation_source = \"valid\"\n",
    "        print(\"Trovata cartella 'valid', verr√† usata come validation set.\")\n",
    "    elif os.path.exists(os.path.join(base_path, \"val\")):\n",
    "        mappatura['val'] = ['split12', 'split13']    # Usa 'val' come chiave se esiste gi√†\n",
    "        validation_source = \"val\"\n",
    "        print(\"Trovata cartella 'val', verr√† usata come validation set.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Attenzione: nessuna cartella 'valid' o 'val' trovata!\")\n",
    "        validation_source = None\n",
    "    \n",
    "    # Contatori\n",
    "    stats = {'train': 0, 'val': 0, 'test': 0}\n",
    "    \n",
    "    # Processa ogni split\n",
    "    for set_name, splits in mappatura.items():\n",
    "        # Determina la destinazione (sempre 'val' per il validation set)\n",
    "        dest_set = \"val\" if set_name in [\"valid\", \"val\"] else set_name\n",
    "        \n",
    "        for split in splits:\n",
    "            split_path = os.path.join(base_path, set_name, split)\n",
    "            \n",
    "            if not os.path.exists(split_path):\n",
    "                print(f\"Split non trovato: {split_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Trova tutti i file PNG\n",
    "            img_files = [f for f in os.listdir(split_path) if f.endswith('.png')]\n",
    "            \n",
    "            for img_file in img_files:\n",
    "                img_path = os.path.join(split_path, img_file)\n",
    "                txt_file = img_file.replace('.png', '.txt')\n",
    "                txt_path = os.path.join(split_path, txt_file)\n",
    "                \n",
    "                # Copia solo se esiste il file di annotazione\n",
    "                if os.path.exists(txt_path):\n",
    "                    # 1. Copia immagine\n",
    "                    dest_img = f\"{output_path}/images/{dest_set}/{img_file}\"\n",
    "                    shutil.copy(img_path, dest_img)\n",
    "                    \n",
    "                    # 2. Leggi dimensioni immagine\n",
    "                    try:\n",
    "                        img = Image.open(img_path)\n",
    "                        img_width, img_height = img.size\n",
    "                        img.close()\n",
    "                        \n",
    "                        # 3. Converti e scrivi annotazioni\n",
    "                        with open(txt_path, 'r') as f_in:\n",
    "                            yolo_lines = []\n",
    "                            \n",
    "                            for line in f_in:\n",
    "                                parts = line.strip().split()\n",
    "                                if len(parts) >= 5:\n",
    "                                    try:\n",
    "                                        # Estrai classe e coordinate\n",
    "                                        class_id = int(parts[0])\n",
    "                                        left = int(parts[1])\n",
    "                                        right = int(parts[2])\n",
    "                                        top = int(parts[3])\n",
    "                                        bottom = int(parts[4])\n",
    "                                        \n",
    "                                        # Converti classe per YOLO\n",
    "                                        # 1 (caduta) -> 1, -1 (non-caduta) -> 0\n",
    "                                        yolo_class = 1 if class_id == 1 else 0\n",
    "                                        \n",
    "                                        # Calcola coordinate normalizzate per YOLO\n",
    "                                        # Formato YOLO: <class> <x_center> <y_center> <width> <height>\n",
    "                                        x_center = (left + right) / 2 / img_width\n",
    "                                        y_center = (top + bottom) / 2 / img_height\n",
    "                                        width = (right - left) / img_width\n",
    "                                        height = (bottom - top) / img_height\n",
    "                                        \n",
    "                                        # Aggiungi linea nel formato YOLO\n",
    "                                        yolo_line = f\"{yolo_class} {x_center} {y_center} {width} {height}\\n\"\n",
    "                                        yolo_lines.append(yolo_line)\n",
    "                                    except:\n",
    "                                        continue\n",
    "                            \n",
    "                            # Scrivi file di annotazione YOLO\n",
    "                            if yolo_lines:\n",
    "                                with open(f\"{output_path}/labels/{dest_set}/{txt_file}\", 'w') as f_out:\n",
    "                                    f_out.writelines(yolo_lines)\n",
    "                                    stats[dest_set] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Errore processing {img_path}: {e}\")\n",
    "    \n",
    "    # Crea file data.yaml per YOLOv11\n",
    "    yaml_content = f\"\"\"\n",
    "# Dataset for Fallen People Detection\n",
    "path: {os.path.abspath(output_path)}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: not_fallen\n",
    "  1: fallen\n",
    "\n",
    "# Info\n",
    "\"\"\"\n",
    "    \n",
    "    with open(f\"{output_path}/data.yaml\", 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    print(\"\\n‚úÖ CONVERSIONE COMPLETATA\")\n",
    "    print(f\"Immagini train: {stats['train']}\")\n",
    "    print(f\"Immagini val: {stats['val']} (da: {validation_source})\")\n",
    "    print(f\"Immagini test: {stats['test']}\")\n",
    "    print(f\"File data.yaml creato in: {output_path}/data.yaml\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Esegui conversione\n",
    "stats = converti_annotazioni_yolo(\"Datasets/E-FPDS\", \"Datasets/yolo_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0e27c",
   "metadata": {},
   "source": [
    "# 2. Installazione di YOLOv11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778c21d",
   "metadata": {},
   "source": [
    "# 3. Training del Modello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a9e04",
   "metadata": {},
   "source": [
    "### 3.1 Balancing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b2448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_dataset(source_path, dest_path, balance_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Crea un dataset perfettamente bilanciato con la percentuale specificata per ogni classe.\n",
    "    \n",
    "    Args:\n",
    "        source_path: Path del dataset originale (formato YOLO)\n",
    "        dest_path: Path dove salvare il dataset bilanciato\n",
    "        balance_ratio: Rapporto desiderato (0.5 per 50/50)\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Creazione dataset bilanciato ({balance_ratio*100:.0f}% cadute / {(1-balance_ratio)*100:.0f}% non cadute)\")\n",
    "    \n",
    "    # 1. Crea struttura directory\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        os.makedirs(os.path.join(dest_path, 'images', split), exist_ok=True)\n",
    "        os.makedirs(os.path.join(dest_path, 'labels', split), exist_ok=True)\n",
    "    \n",
    "    # 2. Analizza le etichette esistenti e classifica le immagini\n",
    "    dataset_map = {'train': {}, 'val': {}, 'test': {}}\n",
    "    image_classes = {'train': {'fallen': [], 'not_fallen': []}, \n",
    "                    'val': {'fallen': [], 'not_fallen': []}, \n",
    "                    'test': {'fallen': [], 'not_fallen': []}}\n",
    "    \n",
    "    print(\"Analisi dataset originale...\")\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        # Trova tutti i file di etichette\n",
    "        label_dir = os.path.join(source_path, 'labels', split)\n",
    "        image_dir = os.path.join(source_path, 'images', split)\n",
    "        \n",
    "        if not os.path.exists(label_dir) or not os.path.exists(image_dir):\n",
    "            print(f\"‚ö†Ô∏è Directory {split} non trovata, saltata\")\n",
    "            continue\n",
    "        \n",
    "        # Analizza ogni file di etichette\n",
    "        for label_file in tqdm(os.listdir(label_dir), desc=f\"Analisi {split}\"):\n",
    "            if not label_file.endswith('.txt'):\n",
    "                continue\n",
    "                \n",
    "            image_base = label_file.replace('.txt', '')\n",
    "            img_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "            img_file = None\n",
    "            \n",
    "            # Trova immagine corrispondente\n",
    "            for ext in img_extensions:\n",
    "                candidate = image_base + ext\n",
    "                if os.path.exists(os.path.join(image_dir, candidate)):\n",
    "                    img_file = candidate\n",
    "                    break\n",
    "            \n",
    "            if not img_file:\n",
    "                continue  # Salta se non trova l'immagine\n",
    "            \n",
    "            # Leggi il file di etichette per determinare la classe\n",
    "            with open(os.path.join(label_dir, label_file), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                \n",
    "                # Controlla ogni bbox nell'immagine\n",
    "                has_fallen = False\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        class_id = int(parts[0])\n",
    "                        if class_id == 0:  # classe 'fallen' in formato YOLO\n",
    "                            has_fallen = True\n",
    "                            break\n",
    "                \n",
    "                # Assegna immagine alla categoria appropriata\n",
    "                category = 'fallen' if has_fallen else 'not_fallen'\n",
    "                image_classes[split][category].append({\n",
    "                    'img': os.path.join(image_dir, img_file),\n",
    "                    'label': os.path.join(label_dir, label_file)\n",
    "                })\n",
    "    \n",
    "    # 3. Stampa statistiche originali\n",
    "    print(\"\\nüìä STATISTICHE DATASET ORIGINALE:\")\n",
    "    total_fallen = sum(len(image_classes[s]['fallen']) for s in ['train', 'val', 'test'])\n",
    "    total_not_fallen = sum(len(image_classes[s]['not_fallen']) for s in ['train', 'val', 'test'])\n",
    "    total_images = total_fallen + total_not_fallen\n",
    "    \n",
    "    print(f\"Totale immagini: {total_images}\")\n",
    "    print(f\"Cadute: {total_fallen} ({total_fallen/total_images*100:.1f}%)\")\n",
    "    print(f\"Non cadute: {total_not_fallen} ({total_not_fallen/total_images*100:.1f}%)\")\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        fallen = len(image_classes[split]['fallen'])\n",
    "        not_fallen = len(image_classes[split]['not_fallen'])\n",
    "        total = fallen + not_fallen\n",
    "        if total > 0:\n",
    "            print(f\"\\n{split.upper()}:\")\n",
    "            print(f\"  Cadute: {fallen} ({fallen/total*100:.1f}%)\")\n",
    "            print(f\"  Non cadute: {not_fallen} ({not_fallen/total*100:.1f}%)\")\n",
    "    \n",
    "    # 4. Bilancia ogni split mantenendo la dimensione originale\n",
    "    balanced_stats = {'train': {'fallen': 0, 'not_fallen': 0},\n",
    "                     'val': {'fallen': 0, 'not_fallen': 0},\n",
    "                     'test': {'fallen': 0, 'not_fallen': 0}}\n",
    "    \n",
    "    print(\"\\nüîÑ BILANCIAMENTO DATASET...\")\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        print(f\"\\nBilanciamento {split}:\")\n",
    "        \n",
    "        # Calcola il numero totale di immagini da mantenere per questo split\n",
    "        fallen = len(image_classes[split]['fallen'])\n",
    "        not_fallen = len(image_classes[split]['not_fallen'])\n",
    "        total_orig = fallen + not_fallen\n",
    "        \n",
    "        if total_orig == 0:\n",
    "            print(f\"  Saltato: nessuna immagine in {split}\")\n",
    "            continue\n",
    "            \n",
    "        # Determina il numero target di immagini per ogni classe\n",
    "        # Strategia: manteniamo lo stesso numero totale ma ribilanciamo\n",
    "        total_target = total_orig  # Mantenere la dimensione originale\n",
    "        fallen_target = int(total_target * balance_ratio)\n",
    "        not_fallen_target = total_target - fallen_target\n",
    "        \n",
    "        # Calcola quante immagini aggiungere o rimuovere per ogni classe\n",
    "        # Motivazione: Usiamo la strategia pi√π conservativa tra over/under sampling\n",
    "        if fallen > fallen_target:\n",
    "            # Downsampling della classe fallen\n",
    "            fallen_indices = random.sample(range(fallen), fallen_target)\n",
    "            fallen_samples = [image_classes[split]['fallen'][i] for i in fallen_indices]\n",
    "            print(f\"  Downsampling cadute: {fallen} ‚Üí {fallen_target}\")\n",
    "        else:\n",
    "            # Upsampling della classe fallen\n",
    "            # Usa tutte le immagini originali\n",
    "            fallen_samples = image_classes[split]['fallen'].copy()\n",
    "            # Aggiungi duplicati con augmentation fino a raggiungere il target\n",
    "            needed = fallen_target - fallen\n",
    "            print(f\"  Upsampling cadute: {fallen} ‚Üí {fallen_target} (+ {needed} copie con augmentation)\")\n",
    "            \n",
    "            # Se servono duplicati, scegli immagini casuali e applica augmentation\n",
    "            if needed > 0:\n",
    "                for _ in range(needed):\n",
    "                    # Scegli immagine casuale da duplicare\n",
    "                    original = random.choice(image_classes[split]['fallen'])\n",
    "                    fallen_samples.append(original)  # Per semplicit√†, aggiungiamo l'originale\n",
    "                    # Nella versione reale, qui applicheremmo augmentation\n",
    "        \n",
    "        if not_fallen > not_fallen_target:\n",
    "            # Downsampling della classe not_fallen\n",
    "            not_fallen_indices = random.sample(range(not_fallen), not_fallen_target)\n",
    "            not_fallen_samples = [image_classes[split]['not_fallen'][i] for i in not_fallen_indices]\n",
    "            print(f\"  Downsampling non cadute: {not_fallen} ‚Üí {not_fallen_target}\")\n",
    "        else:\n",
    "            # Upsampling della classe not_fallen\n",
    "            not_fallen_samples = image_classes[split]['not_fallen'].copy()\n",
    "            needed = not_fallen_target - not_fallen\n",
    "            print(f\"  Upsampling non cadute: {not_fallen} ‚Üí {not_fallen_target} (+ {needed} copie con augmentation)\")\n",
    "            \n",
    "            # Se servono duplicati\n",
    "            if needed > 0:\n",
    "                for _ in range(needed):\n",
    "                    original = random.choice(image_classes[split]['not_fallen'])\n",
    "                    not_fallen_samples.append(original)  # Per semplicit√†\n",
    "        \n",
    "        # 5. Copia i file selezionati nel nuovo dataset\n",
    "        print(f\"  Copia files per {split}...\")\n",
    "        \n",
    "        # Copia immagini cadute\n",
    "        for idx, sample in enumerate(tqdm(fallen_samples, desc=\"Copia cadute\")):\n",
    "            img_src = sample['img']\n",
    "            label_src = sample['label']\n",
    "            \n",
    "            img_extension = os.path.splitext(img_src)[1]\n",
    "            \n",
    "            # Se √® un duplicato, aggiungi un suffisso\n",
    "            img_filename = f\"{split}_fallen_{idx}{img_extension}\"\n",
    "            label_filename = f\"{split}_fallen_{idx}.txt\"\n",
    "            \n",
    "            # Copia immagine\n",
    "            shutil.copy2(img_src, os.path.join(dest_path, 'images', split, img_filename))\n",
    "            \n",
    "            # Copia e modifica etichetta\n",
    "            with open(label_src, 'r') as src_f:\n",
    "                with open(os.path.join(dest_path, 'labels', split, label_filename), 'w') as dst_f:\n",
    "                    for line in src_f:\n",
    "                        dst_f.write(line)  # Conserva l'etichetta originale\n",
    "            \n",
    "            balanced_stats[split]['fallen'] += 1\n",
    "        \n",
    "        # Copia immagini non cadute\n",
    "        for idx, sample in enumerate(tqdm(not_fallen_samples, desc=\"Copia non cadute\")):\n",
    "            img_src = sample['img']\n",
    "            label_src = sample['label']\n",
    "            \n",
    "            img_extension = os.path.splitext(img_src)[1]\n",
    "            \n",
    "            # Se √® un duplicato, aggiungi un suffisso\n",
    "            img_filename = f\"{split}_not_fallen_{idx}{img_extension}\"\n",
    "            label_filename = f\"{split}_not_fallen_{idx}.txt\"\n",
    "            \n",
    "            # Copia immagine\n",
    "            shutil.copy2(img_src, os.path.join(dest_path, 'images', split, img_filename))\n",
    "            \n",
    "            # Copia e modifica etichetta\n",
    "            with open(label_src, 'r') as src_f:\n",
    "                with open(os.path.join(dest_path, 'labels', split, label_filename), 'w') as dst_f:\n",
    "                    for line in src_f:\n",
    "                        dst_f.write(line)  # Conserva l'etichetta originale\n",
    "            \n",
    "            balanced_stats[split]['not_fallen'] += 1\n",
    "    \n",
    "    # 6. Crea file data.yaml per il dataset bilanciato\n",
    "    yaml_content = f\"\"\"\n",
    "# Dataset for Fallen People Detection (Balanced 50/50)\n",
    "path: {os.path.abspath(dest_path)}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: not_fallen\n",
    "  1: fallen\n",
    "\n",
    "# Info\n",
    "\"\"\"\n",
    "    \n",
    "    with open(os.path.join(dest_path, 'data.yaml'), 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    # 7. Stampa statistiche finali\n",
    "    print(\"\\n‚úÖ DATASET BILANCIATO CREATO\")\n",
    "    print(\"\\nüìä STATISTICHE DATASET BILANCIATO:\")\n",
    "    total_bal_fallen = sum(balanced_stats[s]['fallen'] for s in ['train', 'val', 'test'])\n",
    "    total_bal_not_fallen = sum(balanced_stats[s]['not_fallen'] for s in ['train', 'val', 'test'])\n",
    "    total_bal = total_bal_fallen + total_bal_not_fallen\n",
    "    \n",
    "    print(f\"Totale immagini: {total_bal}\")\n",
    "    print(f\"Cadute: {total_bal_fallen} ({total_bal_fallen/total_bal*100:.1f}%)\")\n",
    "    print(f\"Non cadute: {total_bal_not_fallen} ({total_bal_not_fallen/total_bal*100:.1f}%)\")\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        fallen = balanced_stats[split]['fallen']\n",
    "        not_fallen = balanced_stats[split]['not_fallen']\n",
    "        total = fallen + not_fallen\n",
    "        if total > 0:\n",
    "            print(f\"\\n{split.upper()}:\")\n",
    "            print(f\"  Cadute: {fallen} ({fallen/total*100:.1f}%)\")\n",
    "            print(f\"  Non cadute: {not_fallen} ({not_fallen/total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nDataset bilanciato salvato in: {dest_path}\")\n",
    "    print(f\"File data.yaml creato in: {os.path.join(dest_path, 'data.yaml')}\")\n",
    "    \n",
    "    return balanced_stats\n",
    "\n",
    "# Esempio di utilizzo\n",
    "balanced_stats = create_balanced_dataset(\n",
    "    source_path=\"Datasets/yolo_dataset\", \n",
    "    dest_path=\"Datasets/balanced_yolo_dataset\",\n",
    "    balance_ratio=0.5  # 50% cadute, 50% non cadute\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049257e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dati, bboxes, distribuzione_bbox = analizza_dataset(\n",
    "    \"Datasets/balanced_yolo_dataset\", \n",
    "    formato=\"yolo\",\n",
    "    classi_yolo={1: 'caduta', 0: 'non_caduta'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0628e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazioni\n",
    "visualizza_statistiche(dati, bboxes, distribuzione_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfcb764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizza_multipli_bbox_per_set(dati, distribuzione_bbox):\n",
    "    \"\"\"Analizza e visualizza la distribuzione dei multipli bounding box per ogni set.\n",
    "    \n",
    "    Args:\n",
    "        dati: Dizionario con statistiche del dataset per set\n",
    "        distribuzione_bbox: Dizionario con distribuzioni di bounding box per immagine\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Verifica che ci siano dati di distribuzione\n",
    "    if distribuzione_bbox is None or 'total' not in distribuzione_bbox or len(distribuzione_bbox['total']) == 0:\n",
    "        print(\"Nessun dato di distribuzione disponibile per l'analisi\")\n",
    "        return\n",
    "    \n",
    "    # Assicuriamoci che i dati siano in formato numpy array\n",
    "    if not isinstance(distribuzione_bbox['total'], np.ndarray):\n",
    "        distribuzione_bbox['total'] = np.array(distribuzione_bbox['total'], dtype=int)\n",
    "    if not isinstance(distribuzione_bbox['fallen'], np.ndarray):\n",
    "        distribuzione_bbox['fallen'] = np.array(distribuzione_bbox['fallen'], dtype=int)\n",
    "    if not isinstance(distribuzione_bbox['not_fallen'], np.ndarray):\n",
    "        distribuzione_bbox['not_fallen'] = np.array(distribuzione_bbox['not_fallen'], dtype=int)\n",
    "    \n",
    "    # Trova i set presenti nei dati\n",
    "    set_presenti = sorted([s for s in dati.keys() if dati[s]['immagini'] > 0])\n",
    "    \n",
    "    # Gestione caso in cui 'set_info' non √® presente (per compatibilit√† con dati analizzati in precedenza)\n",
    "    if 'set_info' not in distribuzione_bbox:\n",
    "        print(\"\\nATTENZIONE: Informazioni sui set non disponibili nei dati di distribuzione.\")\n",
    "        print(\"√à necessario eseguire nuovamente l'analisi utilizzando la versione aggiornata della funzione 'analizza_dataset'.\")\n",
    "        \n",
    "        # Creiamo un'analisi aggregata invece di per-set\n",
    "        print(\"\\n--- ANALISI AGGREGATA MULTIPLI BOUNDING BOX ---\")\n",
    "        \n",
    "        # Calcola statistiche generali\n",
    "        total_bbox = distribuzione_bbox['total']\n",
    "        fallen_bbox = distribuzione_bbox['fallen']\n",
    "        not_fallen_bbox = distribuzione_bbox['not_fallen']\n",
    "        \n",
    "        total_imgs = len(total_bbox)\n",
    "        multi_bbox = np.sum(total_bbox > 1)\n",
    "        multi_fallen = np.sum(fallen_bbox > 1)\n",
    "        multi_not_fallen = np.sum(not_fallen_bbox > 1)\n",
    "        with_both = np.sum((fallen_bbox > 0) & (not_fallen_bbox > 0))\n",
    "        \n",
    "        pct_multi = (multi_bbox / total_imgs) * 100 if total_imgs > 0 else 0\n",
    "        pct_multi_fallen = (multi_fallen / total_imgs) * 100 if total_imgs > 0 else 0\n",
    "        pct_multi_not_fallen = (multi_not_fallen / total_imgs) * 100 if total_imgs > 0 else 0\n",
    "        pct_both = (with_both / total_imgs) * 100 if total_imgs > 0 else 0\n",
    "        \n",
    "        # Visualizza statistiche aggregate\n",
    "        print(f\"Totale immagini: {total_imgs}\")\n",
    "        print(f\"Immagini con multipli bbox: {multi_bbox} ({pct_multi:.1f}%)\")\n",
    "        print(f\"Immagini con multiple cadute: {multi_fallen} ({pct_multi_fallen:.1f}%)\")\n",
    "        print(f\"Immagini con multiple non-cadute: {multi_not_fallen} ({pct_multi_not_fallen:.1f}%)\")\n",
    "        print(f\"Immagini con entrambe le classi: {with_both} ({pct_both:.1f}%)\")\n",
    "        \n",
    "        # Crea grafici aggregati\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # 1. Grafico distribuzione del numero totale di bbox\n",
    "        plt.subplot(2, 2, 1)\n",
    "        max_bbox = int(np.max(total_bbox)) if len(total_bbox) > 0 else 0\n",
    "        bins = range(0, max_bbox + 2)\n",
    "        \n",
    "        plt.hist(total_bbox, bins=bins, alpha=0.7, color='blue', align='left', rwidth=0.8)\n",
    "        plt.xlabel('Numero di bbox per immagine')\n",
    "        plt.ylabel('Frequenza')\n",
    "        plt.title('Distribuzione del Numero Totale di Bounding Box')\n",
    "        plt.xticks(range(0, max_bbox + 1))\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.annotate(f'Immagini con multipli bbox: {multi_bbox} ({pct_multi:.1f}%)', \n",
    "                     xy=(0.5, 0.9), xycoords='axes fraction', \n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", alpha=0.3),\n",
    "                     ha='center')\n",
    "        \n",
    "        # 2. Grafico distribuzione del numero di bbox per classe\n",
    "        plt.subplot(2, 2, 2)\n",
    "        max_fallen = int(np.max(fallen_bbox)) if len(fallen_bbox) > 0 else 0\n",
    "        max_not_fallen = int(np.max(not_fallen_bbox)) if len(not_fallen_bbox) > 0 else 0\n",
    "        max_class = max(max_fallen, max_not_fallen)\n",
    "        bins = range(0, max_class + 2)\n",
    "        \n",
    "        plt.hist([fallen_bbox, not_fallen_bbox], \n",
    "                 bins=bins, alpha=0.7, \n",
    "                 label=['Cadute', 'Non-cadute'], \n",
    "                 color=['red', 'green'], \n",
    "                 align='left', rwidth=0.8)\n",
    "        \n",
    "        plt.xlabel('Numero di bbox per immagine')\n",
    "        plt.ylabel('Frequenza')\n",
    "        plt.title('Distribuzione del Numero di Bounding Box per Classe')\n",
    "        plt.xticks(range(0, max_class + 1))\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.annotate(f'Multiple cadute: {multi_fallen} ({pct_multi_fallen:.1f}%)\\n'\n",
    "                     f'Multiple non-cadute: {multi_not_fallen} ({pct_multi_not_fallen:.1f}%)\\n'\n",
    "                     f'Con entrambe le classi: {with_both} ({pct_both:.1f}%)', \n",
    "                     xy=(0.5, 0.85), xycoords='axes fraction', \n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", alpha=0.3),\n",
    "                     ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    # Se 'set_info' √® presente, procedi con l'analisi per set\n",
    "    # Crea una figura per la distribuzione di bbox totali per set\n",
    "    plt.figure(figsize=(18, 15))\n",
    "    \n",
    "    # Calcola il massimo numero di bbox per definire i bins\n",
    "    max_bbox = int(np.max(distribuzione_bbox['total'])) if len(distribuzione_bbox['total']) > 0 else 0\n",
    "    \n",
    "    # 1. ANALISI DEI BBOX TOTALI PER SET\n",
    "    for i, set_nome in enumerate(set_presenti):\n",
    "        if set_nome not in ['train', 'test', 'valid', 'val']:\n",
    "            continue\n",
    "            \n",
    "        # Indici delle immagini che appartengono a questo set\n",
    "        indici_set = [idx for idx, s in distribuzione_bbox['set_info'].items() if s == set_nome]\n",
    "        \n",
    "        if not indici_set:\n",
    "            continue\n",
    "            \n",
    "        # Ottieni la distribuzione per questo set\n",
    "        total_bbox_set = distribuzione_bbox['total'][indici_set]\n",
    "        fallen_bbox_set = distribuzione_bbox['fallen'][indici_set]\n",
    "        not_fallen_bbox_set = distribuzione_bbox['not_fallen'][indici_set]\n",
    "        \n",
    "        # Grafico per i bbox totali\n",
    "        plt.subplot(3, 2, i + 1)\n",
    "        bins = range(0, max_bbox + 2)\n",
    "        \n",
    "        plt.hist(total_bbox_set, bins=bins, alpha=0.7, color='blue', align='left', rwidth=0.8)\n",
    "        \n",
    "        plt.xlabel('Numero di bbox per immagine')\n",
    "        plt.ylabel('Frequenza')\n",
    "        plt.title(f'Distribuzione Bbox Totali - {set_nome.upper()}')\n",
    "        plt.xticks(range(0, max_bbox + 1))\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Statistiche sui multipli bbox\n",
    "        multi_bbox = np.sum(total_bbox_set > 1)\n",
    "        pct_multi = (multi_bbox / len(total_bbox_set)) * 100 if len(total_bbox_set) > 0 else 0\n",
    "        \n",
    "        plt.annotate(f'Immagini con multipli bbox: {multi_bbox} ({pct_multi:.1f}%)', \n",
    "                     xy=(0.5, 0.9), xycoords='axes fraction', \n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", alpha=0.3),\n",
    "                     ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Distribuzione del Numero di Bounding Box Totali per Set', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. ANALISI DEI BBOX PER CLASSE E PER SET\n",
    "    plt.figure(figsize=(18, 15))\n",
    "    \n",
    "    max_fallen = int(np.max(distribuzione_bbox['fallen'])) if len(distribuzione_bbox['fallen']) > 0 else 0\n",
    "    max_not_fallen = int(np.max(distribuzione_bbox['not_fallen'])) if len(distribuzione_bbox['not_fallen']) > 0 else 0\n",
    "    max_class = max(max_fallen, max_not_fallen)\n",
    "    \n",
    "    for i, set_nome in enumerate(set_presenti):\n",
    "        if set_nome not in ['train', 'test', 'valid', 'val']:\n",
    "            continue\n",
    "            \n",
    "        # Indici delle immagini che appartengono a questo set\n",
    "        indici_set = [idx for idx, s in distribuzione_bbox['set_info'].items() if s == set_nome]\n",
    "        \n",
    "        if not indici_set:\n",
    "            continue\n",
    "            \n",
    "        # Ottieni la distribuzione per questo set\n",
    "        fallen_bbox_set = distribuzione_bbox['fallen'][indici_set]\n",
    "        not_fallen_bbox_set = distribuzione_bbox['not_fallen'][indici_set]\n",
    "        \n",
    "        # Grafico per i bbox per classe\n",
    "        plt.subplot(3, 2, i + 1)\n",
    "        bins = range(0, max_class + 2)\n",
    "        \n",
    "        plt.hist([fallen_bbox_set, not_fallen_bbox_set], \n",
    "                 bins=bins, alpha=0.7, \n",
    "                 label=['Cadute', 'Non-cadute'], \n",
    "                 color=['red', 'green'], \n",
    "                 align='left', rwidth=0.8)\n",
    "        \n",
    "        plt.xlabel('Numero di bbox per immagine')\n",
    "        plt.ylabel('Frequenza')\n",
    "        plt.title(f'Distribuzione Bbox per Classe - {set_nome.upper()}')\n",
    "        plt.xticks(range(0, max_class + 1))\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Statistiche sui multipli bbox per classe\n",
    "        multi_fallen = np.sum(fallen_bbox_set > 1)\n",
    "        multi_not_fallen = np.sum(not_fallen_bbox_set > 1)\n",
    "        \n",
    "        with_fallen = np.sum(fallen_bbox_set > 0)\n",
    "        with_not_fallen = np.sum(not_fallen_bbox_set > 0)\n",
    "        \n",
    "        pct_multi_fallen = (multi_fallen / with_fallen) * 100 if with_fallen > 0 else 0\n",
    "        pct_multi_not_fallen = (multi_not_fallen / with_not_fallen) * 100 if with_not_fallen > 0 else 0\n",
    "        \n",
    "        # Calcola il numero di immagini con entrambi i tipi di bbox\n",
    "        with_both = np.sum((fallen_bbox_set > 0) & (not_fallen_bbox_set > 0))\n",
    "        pct_both = (with_both / len(fallen_bbox_set)) * 100 if len(fallen_bbox_set) > 0 else 0\n",
    "        \n",
    "        plt.annotate(f'Cadute multiple: {multi_fallen} ({pct_multi_fallen:.1f}%)\\n'\n",
    "                     f'Non-cadute multiple: {multi_not_fallen} ({pct_multi_not_fallen:.1f}%)\\n'\n",
    "                     f'Con entrambe le classi: {with_both} ({pct_both:.1f}%)', \n",
    "                     xy=(0.5, 0.85), xycoords='axes fraction', \n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", alpha=0.3),\n",
    "                     ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Distribuzione del Numero di Bounding Box per Classe e per Set', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. TABELLA RIASSUNTIVA\n",
    "    print(\"\\n--- ANALISI MULTIPLI BOUNDING BOX PER SET ---\")\n",
    "    print(\"‚îå\" + \"‚îÄ\" * 100 + \"‚îê\")\n",
    "    print(\"‚îÇ {:<10} ‚îÇ {:<15} ‚îÇ {:<15} ‚îÇ {:<15} ‚îÇ {:<15} ‚îÇ {:<15} ‚îÇ\".format(\n",
    "        \"SET\", \"Tot Immagini\", \"Multi Bbox\", \"Multi Cadute\", \"Multi Non-cadute\", \"Con Entrambe\"))\n",
    "    print(\"‚îú\" + \"‚îÄ\" * 100 + \"‚î§\")\n",
    "    \n",
    "    # Calcola le statistiche per ogni set\n",
    "    for set_nome in set_presenti:\n",
    "        if set_nome not in ['train', 'test', 'valid', 'val']:\n",
    "            continue\n",
    "            \n",
    "        # Indici delle immagini che appartengono a questo set\n",
    "        indici_set = [idx for idx, s in distribuzione_bbox['set_info'].items() if s == set_nome]\n",
    "        \n",
    "        if not indici_set:\n",
    "            continue\n",
    "            \n",
    "        # Statistiche\n",
    "        total_imgs = len(indici_set)\n",
    "        total_bbox_set = distribuzione_bbox['total'][indici_set]\n",
    "        fallen_bbox_set = distribuzione_bbox['fallen'][indici_set]\n",
    "        not_fallen_bbox_set = distribuzione_bbox['not_fallen'][indici_set]\n",
    "        \n",
    "        multi_bbox = np.sum(total_bbox_set > 1)\n",
    "        multi_fallen = np.sum(fallen_bbox_set > 1)\n",
    "        multi_not_fallen = np.sum(not_fallen_bbox_set > 1)\n",
    "        with_both = np.sum((fallen_bbox_set > 0) & (not_fallen_bbox_set > 0))\n",
    "        \n",
    "        pct_multi = (multi_bbox / total_imgs) * 100 if total_imgs > 0 else 0\n",
    "        pct_multi_fallen = (multi_fallen / total_imgs) * 100 if total_imgs > 0 else 0\n",
    "        pct_multi_not_fallen = (multi_not_fallen / total_imgs) * 100 if total_imgs > 0 else 0\n",
    "        pct_both = (with_both / total_imgs) * 100 if total_imgs > 0 else 0\n",
    "        \n",
    "        print(\"‚îÇ {:<10} ‚îÇ {:<15} ‚îÇ {:<15} ‚îÇ {:<15} ‚îÇ {:<15} ‚îÇ {:<15} ‚îÇ\".format(\n",
    "            set_nome.upper(), \n",
    "            f\"{total_imgs}\",\n",
    "            f\"{multi_bbox} ({pct_multi:.1f}%)\",\n",
    "            f\"{multi_fallen} ({pct_multi_fallen:.1f}%)\",\n",
    "            f\"{multi_not_fallen} ({pct_multi_not_fallen:.1f}%)\",\n",
    "            f\"{with_both} ({pct_both:.1f}%)\"))\n",
    "    \n",
    "    print(\"‚îî\" + \"‚îÄ\" * 100 + \"‚îò\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f79410",
   "metadata": {},
   "outputs": [],
   "source": [
    "analizza_multipli_bbox_per_set(dati, distribuzione_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4570c56",
   "metadata": {},
   "source": [
    "### Con GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341efd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Addestramento ottimizzato di un modello YOLO per rilevamento cadute su GPU\n",
    "\"\"\"\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# ========== CONFIGURAZIONE ==========\n",
    "# Percorsi\n",
    "DATA_PATH = 'Datasets/balanced_yolo_dataset/data.yaml'\n",
    "OUTPUT_DIR = 'fallen_people_detection'\n",
    "RUN_NAME = 'fpds_optimized_gpu'\n",
    "\n",
    "# Verifica disponibilit√† GPU\n",
    "have_gpu = torch.cuda.is_available()\n",
    "if have_gpu:\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"üî• GPU disponibile: {gpu_name} ({gpu_count} dispositivi)\")\n",
    "    device = '0'  # Usa la prima GPU\n",
    "else:\n",
    "    print(\"‚ùå GPU non disponibile, si utilizzer√† la CPU\")\n",
    "    device = 'cpu'\n",
    "\n",
    "# Verifica percorsi e dataset\n",
    "print(f\"üîç Verifica configurazione:\")\n",
    "assert os.path.exists(DATA_PATH), f\"File YAML non trovato: {DATA_PATH}\"\n",
    "\n",
    "# Analisi dataset\n",
    "with open(DATA_PATH, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "    print(f\"Dataset path: {data_config['path']}\")\n",
    "    \n",
    "    # Verifica esistenza cartelle\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_path = os.path.join(data_config['path'], f\"images/{split}\")\n",
    "        if os.path.exists(split_path):\n",
    "            n_imgs = len([f for f in os.listdir(split_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"  ‚úì {split}: {n_imgs} immagini\")\n",
    "        else:\n",
    "            print(f\"  ‚úó {split}: directory non trovata: {split_path}\")\n",
    "\n",
    "# Carica modello\n",
    "model_type = 'yolov8s.pt' if have_gpu else 'yolov8n.pt'  # Small per GPU, Nano per CPU\n",
    "model = YOLO(model_type)\n",
    "print(f\"‚úì Modello caricato: {model.type}\")\n",
    "\n",
    "# ========== FUNZIONE PRINCIPALE DI ADDESTRAMENTO ==========\n",
    "def train_fallen_people_detector_gpu():\n",
    "    \"\"\"Addestra un modello su GPU per rilevamento cadute\"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"‚è≥ Inizio addestramento su {device.upper()}...\")\n",
    "    \n",
    "    # Configurazione ottimizzata per GPU\n",
    "    results = model.train(\n",
    "        data=DATA_PATH,\n",
    "        epochs=150,               # Pi√π epoche su GPU per convergenza migliore\n",
    "        imgsz=640,                # Risoluzione pi√π alta per GPU\n",
    "        batch=16 if have_gpu else 4, # Batch pi√π grande per GPU\n",
    "        device=device,            # Dispositivo configurato\n",
    "        workers=8 if have_gpu else os.cpu_count(),  # Workers per data loading\n",
    "        \n",
    "        # Pesi delle classi per bilanciamento (favorisce classe 'cadute')\n",
    "        class_weights={0: 4.0, 1: 1.0},  # 0=cadute, 1=non-cadute (peso maggiore su GPU)\n",
    "        \n",
    "        # Loss e ottimizzazione\n",
    "        optimizer='AdamW',        # Migliore convergenza per dati sbilanciati\n",
    "        lr0=0.001,                # Learning rate iniziale\n",
    "        lrf=0.00001,              # Learning rate finale\n",
    "        weight_decay=0.0005,      # Regolarizzazione\n",
    "        warmup_epochs=3,          # Warm-up\n",
    "        cos_lr=True,              # Learning rate con andamento cosinusoidale\n",
    "        \n",
    "        # Early stopping\n",
    "        patience=20,              # Pi√π pazienza con dataset grande\n",
    "        \n",
    "        # Data augmentation per bilanciamento classi\n",
    "        augment=True,\n",
    "        mosaic=1.0,               # Massimo mosaic \n",
    "        mixup=0.4,                # Aumentato per variet√†\n",
    "        copy_paste=0.4,           # Copia oggetti tra immagini\n",
    "        translate=0.2,            # Traslazione\n",
    "        scale=0.6,                # Scala variabile\n",
    "        fliplr=0.5,               # Flip orizzontale\n",
    "        degrees=5.0,              # Rotazione leggera\n",
    "        \n",
    "        # Favorire il recall (ridurre falsi negativi)\n",
    "        box=0.07,                 # Ridotto ancora di pi√π per favorire detection (default 0.1)\n",
    "        cls=0.6,                  # Aumentato per migliorare classificazione\n",
    "        \n",
    "        # Regolarizzazione aggiuntiva (solo GPU)\n",
    "        dropout=0.0 if device == 'cpu' else 0.05,  # Leggero dropout\n",
    "        \n",
    "        # Logging e salvataggio\n",
    "        project=OUTPUT_DIR,\n",
    "        name=RUN_NAME,\n",
    "        save_period=10,           # Salva ogni 10 epoche\n",
    "        plots=True,               # Genera plots\n",
    "        save=True,                # Salva modello finale\n",
    "        verbose=True              # Log dettagliato\n",
    "    )\n",
    "    \n",
    "    # Calcola tempo totale\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Addestramento completato in: {timedelta(seconds=total_time)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ========== VALIDAZIONE E ANALISI ==========\n",
    "def validate_and_analyze(model):\n",
    "    \"\"\"Valida il modello e analizza i risultati per classe\"\"\"\n",
    "    print(f\"\\nüîç VALIDAZIONE MODELLO\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Valuta sul validation set\n",
    "    print(f\"Valutazione sul validation set...\")\n",
    "    val_results = model.val(\n",
    "        data=DATA_PATH,\n",
    "        split='val',\n",
    "        conf=0.25,        # Soglia confidenza ridotta per cadute\n",
    "        iou=0.6,          # IoU threshold\n",
    "        max_det=300,      # Aumentato per scenari con molte persone\n",
    "        device=device,    # Stesso dispositivo di training\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Estrai metriche per classe\n",
    "    metrics_per_class = {}\n",
    "    try:\n",
    "        # Precision per classe\n",
    "        metrics_per_class['precision'] = val_results.box.mp_per_class.tolist() if hasattr(val_results.box, 'mp_per_class') else None\n",
    "        # Recall per classe\n",
    "        metrics_per_class['recall'] = val_results.box.mr_per_class.tolist() if hasattr(val_results.box, 'mr_per_class') else None\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Impossibile estrarre metriche per classe\")\n",
    "    \n",
    "    # Stampa metriche generali\n",
    "    print(f\"\\nüìä METRICHE GENERALI:\")\n",
    "    print(f\"mAP50: {val_results.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {val_results.box.map:.4f}\")\n",
    "    print(f\"Precision: {val_results.box.mp:.4f}\")\n",
    "    print(f\"Recall: {val_results.box.mr:.4f}\")\n",
    "    \n",
    "    # Stampa metriche per classe\n",
    "    if metrics_per_class.get('precision') and metrics_per_class.get('recall'):\n",
    "        print(f\"\\nüìä METRICHE PER CLASSE:\")\n",
    "        class_names = ['fallen', 'not_fallen']\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            print(f\"{class_name}:\")\n",
    "            print(f\"  Precision: {metrics_per_class['precision'][i]:.4f}\")\n",
    "            print(f\"  Recall: {metrics_per_class['recall'][i]:.4f}\")\n",
    "            print(f\"  F1-Score: {2*(metrics_per_class['precision'][i]*metrics_per_class['recall'][i])/(metrics_per_class['precision'][i]+metrics_per_class['recall'][i]):.4f}\")\n",
    "    \n",
    "    # Valuta anche sul test set\n",
    "    print(f\"\\nüîç Valutazione sul test set...\")\n",
    "    test_results = model.val(\n",
    "        data=DATA_PATH,\n",
    "        split='test',\n",
    "        conf=0.25,\n",
    "        iou=0.6,\n",
    "        device=device,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Test su alcuni esempi\n",
    "    print(f\"\\nüñºÔ∏è TEST SU ESEMPI:\")\n",
    "    test_dir = os.path.join(data_config['path'], 'images/test')\n",
    "    if os.path.exists(test_dir):\n",
    "        # Prendi massimo 5 immagini di test casuali\n",
    "        import random\n",
    "        test_images = [os.path.join(test_dir, f) for f in os.listdir(test_dir) \n",
    "                     if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        if test_images:\n",
    "            random.shuffle(test_images)\n",
    "            test_images = test_images[:5]\n",
    "            \n",
    "            for img_path in test_images:\n",
    "                print(f\"Predizione su: {os.path.basename(img_path)}\")\n",
    "                # Usa soglia confidenza pi√π bassa per classe fallen\n",
    "                results = model.predict(\n",
    "                    source=img_path,\n",
    "                    conf=0.2,      # Soglia bassa per favorire recall\n",
    "                    iou=0.6,\n",
    "                    device=device,\n",
    "                    save=True,\n",
    "                    save_crop=True # Salva ritagli\n",
    "                )\n",
    "                \n",
    "                # Analizza risultati\n",
    "                boxes = results[0].boxes\n",
    "                if len(boxes) > 0:\n",
    "                    for i, box in enumerate(boxes):\n",
    "                        class_id = int(box.cls.item())\n",
    "                        conf = box.conf.item()\n",
    "                        class_name = class_names[class_id]\n",
    "                        print(f\"  Detected: {class_name} (conf: {conf:.2f})\")\n",
    "                else:\n",
    "                    print(\"  Nessun oggetto rilevato\")\n",
    "        else:\n",
    "            print(\"  Nessuna immagine di test trovata\")\n",
    "    \n",
    "    return val_results, test_results\n",
    "\n",
    "# ========== ANALISI SBILANCIAMENTO E THRESHOLD OTTIMALE ==========\n",
    "def analyze_threshold_impact(model):\n",
    "    \"\"\"Analizza l'impatto di diverse soglie di confidenza su precision e recall\"\"\"\n",
    "    print(f\"\\nüìä ANALISI THRESHOLD OTTIMALE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Soglie da testare\n",
    "    thresholds = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5]\n",
    "    results = []\n",
    "    \n",
    "    # Test su validation set\n",
    "    for conf in thresholds:\n",
    "        print(f\"Valutazione con threshold = {conf}\")\n",
    "        val_result = model.val(data=DATA_PATH, conf=conf, iou=0.6, verbose=False)\n",
    "        \n",
    "        # Salva risultati\n",
    "        results.append({\n",
    "            'threshold': conf,\n",
    "            'precision': val_result.box.mp,\n",
    "            'recall': val_result.box.mr,\n",
    "            'map50': val_result.box.map50,\n",
    "            'f1': 2 * (val_result.box.mp * val_result.box.mr) / (val_result.box.mp + val_result.box.mr)\n",
    "        })\n",
    "    \n",
    "    # Crea grafico\n",
    "    thresholds = [r['threshold'] for r in results]\n",
    "    precisions = [r['precision'] for r in results]\n",
    "    recalls = [r['recall'] for r in results]\n",
    "    f1_scores = [r['f1'] for r in results]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, precisions, 'b-', marker='o', label='Precision')\n",
    "    plt.plot(thresholds, recalls, 'r-', marker='o', label='Recall')\n",
    "    plt.plot(thresholds, f1_scores, 'g-', marker='o', label='F1 Score')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.xlabel('Confidence Threshold')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.title('Impact of Confidence Threshold on Metrics')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, RUN_NAME, 'threshold_analysis.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Trova threshold ottimale per F1\n",
    "    best_f1_idx = f1_scores.index(max(f1_scores))\n",
    "    best_f1_threshold = thresholds[best_f1_idx]\n",
    "    \n",
    "    # Trova threshold per recall elevato\n",
    "    high_recall_idx = next((i for i, r in enumerate(recalls) if r > 0.9), 0)\n",
    "    high_recall_threshold = thresholds[high_recall_idx] if high_recall_idx < len(thresholds) else thresholds[0]\n",
    "    \n",
    "    print(f\"\\nüéØ THRESHOLD OTTIMALI:\")\n",
    "    print(f\"Miglior F1 Score: threshold = {best_f1_threshold} (F1 = {max(f1_scores):.4f})\")\n",
    "    print(f\"Alta Recall (safety): threshold = {high_recall_threshold} (Recall = {recalls[high_recall_idx]:.4f})\")\n",
    "    \n",
    "    # Salva risultati in CSV\n",
    "    import csv\n",
    "    with open(os.path.join(OUTPUT_DIR, RUN_NAME, 'threshold_analysis.csv'), 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Threshold', 'Precision', 'Recall', 'mAP50', 'F1'])\n",
    "        for r in results:\n",
    "            writer.writerow([r['threshold'], r['precision'], r['recall'], r['map50'], r['f1']])\n",
    "    \n",
    "    return best_f1_threshold, high_recall_threshold\n",
    "\n",
    "# ========== ESPORTAZIONE E SALVATAGGIO ==========\n",
    "def export_model(model):\n",
    "    \"\"\"Esporta il modello in formati diversi\"\"\"\n",
    "    print(f\"\\nüíæ ESPORTAZIONE MODELLO\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Esporta in ONNX (per deployment)\n",
    "    print(\"Esportazione in ONNX...\")\n",
    "    onnx_path = model.export(format='onnx')\n",
    "    print(f\"‚úì Modello ONNX salvato: {onnx_path}\")\n",
    "    \n",
    "    # Esporta in altri formati utili\n",
    "    if have_gpu:\n",
    "        # TensorRT (solo GPU NVIDIA)\n",
    "        try:\n",
    "            print(\"Esportazione in TensorRT...\")\n",
    "            tensorrt_path = model.export(format='engine')\n",
    "            print(f\"‚úì Modello TensorRT salvato: {tensorrt_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Errore esportazione TensorRT: {e}\")\n",
    "    \n",
    "    # Esporta in Torchscript (per deployment universale)\n",
    "    print(\"Esportazione in TorchScript...\")\n",
    "    try:\n",
    "        torchscript_path = model.export(format='torchscript')\n",
    "        print(f\"‚úì Modello TorchScript salvato: {torchscript_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Errore esportazione TorchScript: {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ MODELLO PRONTO PER L'USO\")\n",
    "    print(f\"Percorso modelli: {os.path.join(OUTPUT_DIR, RUN_NAME)}\")\n",
    "\n",
    "# ========== ESECUZIONE PRINCIPALE ==========\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Addestramento\n",
    "    results = train_fallen_people_detector_gpu()\n",
    "    \n",
    "    # 2. Validazione e analisi\n",
    "    val_results, test_results = validate_and_analyze(model)\n",
    "    \n",
    "    # 3. Analisi threshold ottimale\n",
    "    best_f1_threshold, high_recall_threshold = analyze_threshold_impact(model)\n",
    "    \n",
    "    # 4. Esportazione modello\n",
    "    export_model(model)\n",
    "    \n",
    "    print(\"\\nüéØ ADDESTRAMENTO SU {} COMPLETATO CON SUCCESSO\".format(\"GPU\" if have_gpu else \"CPU\"))\n",
    "    print(f\"Performance migliore (F1): conf={best_f1_threshold}\")\n",
    "    print(f\"Performance safety-critical (Recall): conf={high_recall_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f221f84",
   "metadata": {},
   "source": [
    "### Con CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorsi\n",
    "DATA_PATH = 'Datasets/balanced_yolo_dataset/data.yaml'\n",
    "\n",
    "# Carica modello\n",
    "print(\"Caricamento modello YOLOv11...\")\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Addestramento minimo che sicuramente funziona\n",
    "def train_minimal():\n",
    "    print(\"‚è≥ Inizio addestramento YOLOv11 (configurazione minima)...\")\n",
    "    \n",
    "    # Usa SOLO i parametri core che sicuramente funzionano\n",
    "    results = model.train(\n",
    "        data=DATA_PATH,\n",
    "        epochs=50,          # Numero epoche\n",
    "        imgsz=416,          # Dimensioni ridotte\n",
    "        batch=4,            # Batch piccolo\n",
    "        device='cpu',       # Usa CPU\n",
    "        optimizer='AdamW',  # Ottimizzatore standard\n",
    "        patience=15,        # Early stopping\n",
    "        project='fallen_people_detection',\n",
    "        name='fpds_minimal',\n",
    "        verbose=True        # Log dettagliato\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Addestramento completato!\")\n",
    "    return results\n",
    "\n",
    "# Esegui\n",
    "results = train_minimal()\n",
    "\n",
    "# Valida\n",
    "model.val(data=DATA_PATH)\n",
    "\n",
    "# Test\n",
    "test_dir = os.path.join('Datasets/yolo_dataset/images/test')\n",
    "if os.path.exists(test_dir):\n",
    "    test_files = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.png'))]\n",
    "    if test_files:\n",
    "        model.predict(os.path.join(test_dir, test_files[0]), save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb726d18",
   "metadata": {},
   "source": [
    "# 4. Validazione del Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model=YOLO('v8n_dataset_pierga.pt')\n",
    "\n",
    "# Validazione sul set di validazione\n",
    "val_results = model.val(data='data_pierga_v8n.yaml')\n",
    "\n",
    "# Stampa metriche\n",
    "print(f\"mAP50: {val_results.box.map50}\")\n",
    "print(f\"mAP50-95: {val_results.box.map}\")\n",
    "print(f\"Precision: {val_results.box.mp}\")\n",
    "print(f\"Recall: {val_results.box.mr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057d05d",
   "metadata": {},
   "source": [
    "# 5. Test su Immagini di Esempio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26127e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa il modello su immagini specifiche\n",
    "results = model.predict(source='Datasets/balanced_yolo_dataset/images/test', save=True, conf=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0684c9d9",
   "metadata": {},
   "source": [
    "# 6. Esportazione del Modello\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a156fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esporta il modello in vari formati\n",
    "model.export(format='onnx')  # Esporta in ONNX\n",
    "# Altri formati: 'torchscript', 'tflite', 'coreml', ecc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b522c7c1",
   "metadata": {},
   "source": [
    "# 7. Valutazione su Casi Specifici\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f3e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def test_on_image(model, image_path):\n",
    "    \"\"\"Test del modello su un'immagine specifica con visualizzazione.\"\"\"\n",
    "    # Carica immagine\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Predizione\n",
    "    results = model.predict(image_path, conf=0.25)\n",
    "    \n",
    "    # Visualizza risultati\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(np.array(img))\n",
    "    \n",
    "    # Estrai risultati\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()  # x1, y1, x2, y2\n",
    "    confs = results[0].boxes.conf.cpu().numpy()\n",
    "    cls = results[0].boxes.cls.cpu().numpy()\n",
    "    \n",
    "    # Disegna bounding box\n",
    "    for box, conf, cl in zip(boxes, confs, cls):\n",
    "        x1, y1, x2, y2 = box\n",
    "        color = 'red' if cl == 0 else 'green'\n",
    "        label = f\"{'Caduta' if cl == 0 else 'Non-caduta'}: {conf:.2f}\"\n",
    "        \n",
    "        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                               linewidth=2, edgecolor=color, facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.text(x1, y1-5, label, color=color, fontsize=10,\n",
    "                backgroundcolor='white')\n",
    "    \n",
    "    plt.title(f\"Predizione YOLOv11 su {image_path.split('/')[-1]}\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test su alcune immagini di esempio\n",
    "test_paths = [\n",
    "    'Datasets/balanced_yolo_dataset/images/test/split4_001.png',\n",
    "    'yolo_dataset/images/test/split4_002.png',\n",
    "    'yolo_dataset/images/test/split4_003.png'\n",
    "]\n",
    "\n",
    "for path in test_paths:\n",
    "    test_on_image(model, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55eb13",
   "metadata": {},
   "source": [
    "# 8. Analisi delle Prestazioni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ae84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def performance_analysis(model, test_folder='Datasets/balanced_yolo_dataset/images/test'):\n",
    "    \"\"\"Analisi delle prestazioni del modello.\"\"\"\n",
    "    import os\n",
    "    \n",
    "    y_true = []  # Classi vere\n",
    "    y_pred = []  # Classi predette\n",
    "    \n",
    "    # Processa tutte le immagini di test\n",
    "    for img_file in os.listdir(test_folder):\n",
    "        if not img_file.endswith('.png'):\n",
    "            continue\n",
    "        \n",
    "        img_path = os.path.join(test_folder, img_file)\n",
    "        txt_path = img_path.replace('.png', '.txt').replace('/images/', '/labels/')\n",
    "        \n",
    "        # Leggi vera classe\n",
    "        try:\n",
    "            with open(txt_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    true_class = int(parts[0])\n",
    "                    y_true.append(true_class)\n",
    "                    \n",
    "                    # Predici\n",
    "                    results = model.predict(img_path, conf=0.25)\n",
    "                    \n",
    "                    if len(results[0].boxes) > 0:\n",
    "                        # Prendi la predizione con confidenza pi√π alta\n",
    "                        pred_class = int(results[0].boxes.cls[0].item())\n",
    "                        y_pred.append(pred_class)\n",
    "                    else:\n",
    "                        # Nessuna predizione\n",
    "                        y_pred.append(-1)  # -1 per indicare \"nessuna predizione\"\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Crea confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Visualizza\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Caduta', 'Non-caduta', 'Nessuna pred.'] if -1 in y_pred else ['Caduta', 'Non-caduta'],\n",
    "                yticklabels=['Caduta', 'Non-caduta'])\n",
    "    plt.xlabel('Predetta')\n",
    "    plt.ylabel('Vera')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Report dettagliato\n",
    "    print(\"\\nRAPPORTO CLASSIFICAZIONE:\")\n",
    "    print(classification_report(y_true, [p for p in y_pred if p != -1], \n",
    "                              target_names=['Caduta', 'Non-caduta']))\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "# Esegui analisi\n",
    "y_true, y_pred = performance_analysis(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c65eb3e",
   "metadata": {},
   "source": [
    "# 9. Fine-Tuning per Sicurezza Critica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf970b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestra con focus sul recall (pi√π importante non perdere le cadute)\n",
    "results = model.train(\n",
    "    data='yolo_dataset/data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    # Parametri specifici per bilanciare verso recall\n",
    "    hyp={\n",
    "        'box': 0.1,           # Peso per box loss\n",
    "        'cls': 0.7,           # Peso per class loss (pi√π alto per enfatizzare classificazione corretta)\n",
    "        'cls_pw': 1.0,        # Peso per classe positiva\n",
    "        'obj': 1.0,           # Peso per objectness loss\n",
    "        'obj_pw': 1.0,        # Peso per objectness positivo\n",
    "        'fl_gamma': 0.0,      # Focal loss gamma\n",
    "    },\n",
    "    # Priorit√† alla classe \"caduta\"\n",
    "    class_weights={0: 1.0, 1: 2.0},  # Raddoppia il peso per la classe caduta\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abac2fdf",
   "metadata": {},
   "source": [
    "# 10. Implementazione in Tempo Reale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "def monitor_video_stream(model, source=0):\n",
    "    \"\"\"Monitora uno stream video per rilevare cadute.\"\"\"\n",
    "    import cv2\n",
    "    \n",
    "    # Apri stream video\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        # Leggi frame\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        # Converti colori per YOLOv11\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Predici\n",
    "        results = model.predict(frame_rgb, conf=0.7)\n",
    "        \n",
    "        # Processa risultati\n",
    "        annotated_frame = results[0].plot()\n",
    "        \n",
    "        # Converti colori per visualizzazione\n",
    "        annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Mostra\n",
    "        cv2.imshow(\"YOLOv11 Fallen Person Detection\", annotated_frame)\n",
    "        \n",
    "        # Premi 'q' per uscire\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Rilascia risorse\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "model_path = \"/Users/andreavisi/Desktop/PYTHON/Sistemi operativi Dedicati 2025/PROGETTO/Eyes_on_falls_YOLO/fallen_people_detection/fpds_minimal/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "#model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Avvia monitoraggio (webcam)\n",
    "monitor_video_stream(model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import subprocess\n",
    "import platform\n",
    "\n",
    "def check_system_requirements():\n",
    "    \"\"\"Verifica i requisiti di sistema\"\"\"\n",
    "    print(\"=== Verifica Sistema ===\")\n",
    "    \n",
    "    # Verifica versione macOS\n",
    "    mac_version = platform.mac_ver()[0]\n",
    "    print(f\"Versione macOS: {mac_version}\")\n",
    "    \n",
    "    # Lista camere disponibili\n",
    "    try:\n",
    "        result = subprocess.run(['system_profiler', 'SPCameraDataType'], \n",
    "                              capture_output=True, text=True)\n",
    "        print(\"\\n=== Camere Rilevate ===\")\n",
    "        print(result.stdout)\n",
    "    except:\n",
    "        print(\"Impossibile listare le camere\")\n",
    "\n",
    "def test_all_cameras():\n",
    "    \"\"\"Testa tutti gli indici camera possibili\"\"\"\n",
    "    print(\"\\n=== Test Camere ===\")\n",
    "    \n",
    "    available_cameras = []\n",
    "    \n",
    "    # Prova anche indici negativi (a volte macOS li usa)\n",
    "    for i in range(-5, 10):\n",
    "        cap = cv2.VideoCapture(i)\n",
    "        if cap.isOpened():\n",
    "            width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "            height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "            \n",
    "            # Leggi un frame per verificare che funzioni davvero\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                print(f\"\\n‚úì Camera {i} funzionante:\")\n",
    "                print(f\"  Risoluzione: {int(width)}x{int(height)}\")\n",
    "                \n",
    "                # Mostra preview per identificare quale √® l'iPhone\n",
    "                cv2.putText(frame, f\"Camera Index: {i}\", (10, 30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, \"Premi 'q' per prossima camera\", (10, 60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                \n",
    "                cv2.imshow(f\"Test Camera {i}\", frame)\n",
    "                \n",
    "                key = cv2.waitKey(0) & 0xFF\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "                if key == ord('y'):\n",
    "                    print(f\"  -> Selezionata come iPhone!\")\n",
    "                    available_cameras.append((i, True))\n",
    "                else:\n",
    "                    available_cameras.append((i, False))\n",
    "            \n",
    "            cap.release()\n",
    "    \n",
    "    return available_cameras\n",
    "\n",
    "def use_continuity_camera(model, camera_index):\n",
    "    \"\"\"Usa specificamente Continuity Camera\"\"\"\n",
    "    cap = cv2.VideoCapture(camera_index)\n",
    "    \n",
    "    # Imposta propriet√† per Continuity Camera\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Impossibile aprire camera all'indice {camera_index}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Camera {camera_index} aperta con successo!\")\n",
    "    print(\"Premi 'q' per uscire\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Frame non ricevuto\")\n",
    "            break\n",
    "        \n",
    "        # Fall detection\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = model.predict(frame_rgb, conf=0.4)\n",
    "        annotated_frame = results[0].plot()\n",
    "        annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Aggiungi info\n",
    "        cv2.putText(annotated_frame, \"iPhone via Continuity Camera\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow(\"Fall Detection - iPhone\", annotated_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Esegui diagnostica\n",
    "check_system_requirements()\n",
    "cameras = test_all_cameras()\n",
    "\n",
    "# Carica modello\n",
    "from ultralytics import YOLO\n",
    "model_path = \"/Users/andreavisi/Desktop/PYTHON/Sistemi operativi Dedicati 2025/PROGETTO/Eyes_on_falls_YOLO/fallen_people_detection/fpds_minimal/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Usa la camera selezionata\n",
    "if cameras:\n",
    "    iphone_cameras = [c[0] for c in cameras if c[1]]\n",
    "    if iphone_cameras:\n",
    "        use_continuity_camera(model, iphone_cameras[0])\n",
    "    else:\n",
    "        print(\"\\nNessuna camera identificata come iPhone.\")\n",
    "        print(\"Prova manualmente con questi indici:\", [c[0] for c in cameras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec3347a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Script per analizzare la distribuzione dei dati in un dataset YOLO.\n",
    "Controlla la distribuzione delle classi nelle cartelle train, val e test.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Analizza la distribuzione dei dati in un dataset YOLO')\n",
    "    parser.add_argument('--yaml', type=str, required=True, help='Percorso al file YAML del dataset')\n",
    "    parser.add_argument('--output', type=str, default='dataset_analysis', help='Nome del file di output per i grafici')\n",
    "    return parser.parse_args()\n",
    "\n",
    "def count_objects_in_label_file(label_file, num_classes):\n",
    "    \"\"\"Conta gli oggetti per classe in un file di etichette YOLO\"\"\"\n",
    "    counts = [0] * num_classes\n",
    "    \n",
    "    if not os.path.exists(label_file):\n",
    "        return counts\n",
    "        \n",
    "    try:\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:  # Formato YOLO: class_id x y width height\n",
    "                    class_id = int(parts[0])\n",
    "                    if 0 <= class_id < num_classes:\n",
    "                        counts[class_id] += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nel leggere {label_file}: {e}\")\n",
    "        \n",
    "    return counts\n",
    "\n",
    "def analyze_dataset(data_yaml):\n",
    "    \"\"\"Analizza un dataset YOLO basato sul file YAML\"\"\"\n",
    "    print(f\"üîç Analisi del dataset: {data_yaml}\")\n",
    "    \n",
    "    # Carica configurazione YAML\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    # Ottieni percorso base del dataset\n",
    "    try:\n",
    "        dataset_path = data_config['path']\n",
    "        if not os.path.isabs(dataset_path):\n",
    "            # Se √® un percorso relativo, calcola basandosi sulla posizione del file YAML\n",
    "            yaml_dir = os.path.dirname(os.path.abspath(data_yaml))\n",
    "            dataset_path = os.path.join(yaml_dir, dataset_path)\n",
    "    except KeyError:\n",
    "        # Se 'path' non √® definito, presumi che la directory del YAML sia la root del dataset\n",
    "        dataset_path = os.path.dirname(os.path.abspath(data_yaml))\n",
    "    \n",
    "    print(f\"üìÇ Percorso dataset: {dataset_path}\")\n",
    "    \n",
    "    # Ottieni nomi delle classi\n",
    "    classes = {}\n",
    "    if 'names' in data_config:\n",
    "        if isinstance(data_config['names'], dict):\n",
    "            classes = data_config['names']\n",
    "        elif isinstance(data_config['names'], list):\n",
    "            classes = {i: name for i, name in enumerate(data_config['names'])}\n",
    "        num_classes = len(classes)\n",
    "    else:\n",
    "        # Se non sono specificati nomi, presumi che vengano determinati dai file\n",
    "        print(\"‚ö†Ô∏è Nomi delle classi non specificati nel file YAML\")\n",
    "        # Prova a trovare il numero massimo di classi analizzando alcuni file di etichette\n",
    "        num_classes = 0  # Verr√† aggiornato se vengono trovate classi nei file\n",
    "        \n",
    "    print(f\"üìä Nomi classi: {classes}\")\n",
    "    \n",
    "    results = {}\n",
    "    splits = ['train', 'val', 'test']\n",
    "    \n",
    "    for split in splits:\n",
    "        # Percorsi immagini e etichette\n",
    "        images_dir = os.path.join(dataset_path, f\"images/{split}\")\n",
    "        labels_dir = os.path.join(dataset_path, f\"labels/{split}\")\n",
    "        \n",
    "        if not os.path.exists(images_dir):\n",
    "            print(f\"‚ö†Ô∏è Directory immagini non trovata: {images_dir}\")\n",
    "            continue\n",
    "            \n",
    "        if not os.path.exists(labels_dir):\n",
    "            print(f\"‚ö†Ô∏è Directory etichette non trovata: {labels_dir}\")\n",
    "            continue\n",
    "        \n",
    "        # Conta le immagini\n",
    "        image_files = [f for f in os.listdir(images_dir) \n",
    "                       if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "        num_images = len(image_files)\n",
    "        \n",
    "        # Inizializza contatori per le classi\n",
    "        class_counts = [0] * num_classes\n",
    "        images_with_class = [0] * num_classes\n",
    "        total_objects = 0\n",
    "        \n",
    "        # Conta oggetti per classe\n",
    "        for img_file in image_files:\n",
    "            # Converti l'estensione del file immagine in .txt per il file etichetta\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            label_file = os.path.join(labels_dir, f\"{base_name}.txt\")\n",
    "            \n",
    "            # Conta oggetti nel file di etichetta\n",
    "            obj_counts = count_objects_in_label_file(label_file, num_classes)\n",
    "            \n",
    "            # Aggiorna contatori\n",
    "            for class_id, count in enumerate(obj_counts):\n",
    "                class_counts[class_id] += count\n",
    "                if count > 0:\n",
    "                    images_with_class[class_id] += 1\n",
    "                total_objects += count\n",
    "        \n",
    "        # Se non era specificato il numero di classi, determinalo ora\n",
    "        if num_classes == 0 and max(class_counts, default=0) > 0:\n",
    "            num_classes = max(class_counts) + 1\n",
    "            classes = {i: f\"Classe {i}\" for i in range(num_classes)}\n",
    "            \n",
    "        # Salva risultati\n",
    "        results[split] = {\n",
    "            'num_images': num_images,\n",
    "            'class_counts': class_counts,\n",
    "            'images_with_class': images_with_class,\n",
    "            'total_objects': total_objects,\n",
    "            'objects_per_image': total_objects / num_images if num_images > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # Stampa risultati per questo split\n",
    "        print(f\"\\nüìä Statistiche {split}:\")\n",
    "        print(f\"  üì∑ Immagini totali: {num_images}\")\n",
    "        print(f\"  üè∑Ô∏è Oggetti totali: {total_objects}\")\n",
    "        print(f\"  üìä Media oggetti per immagine: {results[split]['objects_per_image']:.2f}\")\n",
    "        print(f\"  üìà Distribuzione classi:\")\n",
    "        \n",
    "        for class_id, count in enumerate(class_counts):\n",
    "            if class_id < len(classes):\n",
    "                class_name = classes[class_id]\n",
    "                percent = (count / total_objects * 100) if total_objects > 0 else 0\n",
    "                img_percent = (images_with_class[class_id] / num_images * 100) if num_images > 0 else 0\n",
    "                print(f\"    - {class_name}: {count} oggetti ({percent:.1f}%) in {images_with_class[class_id]} immagini ({img_percent:.1f}%)\")\n",
    "    \n",
    "    return results, classes, splits\n",
    "\n",
    "def plot_distribution(results, classes, splits, output_name):\n",
    "    \"\"\"Crea grafici per visualizzare la distribuzione del dataset\"\"\"\n",
    "    if not results:\n",
    "        print(\"‚ùå Nessun dato da visualizzare\")\n",
    "        return\n",
    "    \n",
    "    # Imposta stile Seaborn\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    # Impostazioni figure\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. Grafico a barre distribuzione classi per split\n",
    "    plt.subplot(2, 1, 1)\n",
    "    bar_width = 0.8 / len(splits)\n",
    "    \n",
    "    for i, split in enumerate(splits):\n",
    "        if split not in results:\n",
    "            continue\n",
    "            \n",
    "        data = results[split]\n",
    "        class_counts = data['class_counts']\n",
    "        \n",
    "        x = np.arange(len(classes))\n",
    "        offset = bar_width * (i - len(splits)/2 + 0.5)\n",
    "        plt.bar(x + offset, class_counts, width=bar_width, label=split.capitalize())\n",
    "    \n",
    "    plt.xlabel('Classi', fontsize=12)\n",
    "    plt.ylabel('Numero di oggetti', fontsize=12)\n",
    "    plt.title('Distribuzione degli oggetti per classe', fontsize=14)\n",
    "    plt.xticks(range(len(classes)), [classes[i] for i in range(len(classes))], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 2. Grafico a torta distribuzione generale\n",
    "    plt.subplot(2, 2, 3)\n",
    "    total_counts = [0] * len(classes)\n",
    "    \n",
    "    for split in splits:\n",
    "        if split not in results:\n",
    "            continue\n",
    "        data = results[split]\n",
    "        for i, count in enumerate(data['class_counts']):\n",
    "            if i < len(total_counts):\n",
    "                total_counts[i] += count\n",
    "    \n",
    "    # Crea un grafico a torta solo se ci sono dati\n",
    "    if sum(total_counts) > 0:\n",
    "        plt.pie(total_counts, labels=[classes[i] for i in range(len(classes))], \n",
    "                autopct='%1.1f%%', startangle=90)\n",
    "        plt.axis('equal')\n",
    "        plt.title('Distribuzione complessiva delle classi', fontsize=14)\n",
    "    \n",
    "    # 3. Grafico a barre immagini e oggetti per split\n",
    "    plt.subplot(2, 2, 4)\n",
    "    splits_present = [s for s in splits if s in results]\n",
    "    num_images = [results[s]['num_images'] for s in splits_present]\n",
    "    total_objects = [results[s]['total_objects'] for s in splits_present]\n",
    "    \n",
    "    x = np.arange(len(splits_present))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, num_images, width, label='Immagini')\n",
    "    plt.bar(x + width/2, total_objects, width, label='Oggetti')\n",
    "    \n",
    "    plt.xlabel('Split', fontsize=12)\n",
    "    plt.ylabel('Conteggio', fontsize=12)\n",
    "    plt.title('Immagini e oggetti per split', fontsize=14)\n",
    "    plt.xticks(x, [s.capitalize() for s in splits_present])\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_name}.png\", dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n‚úÖ Grafico salvato come: {output_name}.png\")\n",
    "    \n",
    "    # Mostra il grafico se possibile\n",
    "    try:\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    \n",
    "    # Verifica che il file YAML esista\n",
    "    if not os.path.exists(args.yaml):\n",
    "        print(f\"‚ùå File YAML non trovato: {args.yaml}\")\n",
    "        return\n",
    "    \n",
    "    # Analizza il dataset\n",
    "    results, classes, splits = analyze_dataset(args.yaml)\n",
    "    \n",
    "    # Crea grafici\n",
    "    plot_distribution(results, classes, splits, args.output)\n",
    "    \n",
    "    # Stampa riepilogo bilanciamento\n",
    "    print(\"\\nüìä RIEPILOGO BILANCIAMENTO DATASET:\")\n",
    "    all_class_counts = [0] * len(classes)\n",
    "    \n",
    "    for split in splits:\n",
    "        if split in results:\n",
    "            for i, count in enumerate(results[split]['class_counts']):\n",
    "                if i < len(all_class_counts):\n",
    "                    all_class_counts[i] += count\n",
    "    \n",
    "    total_objs = sum(all_class_counts)\n",
    "    if total_objs > 0:\n",
    "        max_count = max(all_class_counts)\n",
    "        min_count = min(all_class_counts) if min(all_class_counts) > 0 else max_count\n",
    "        imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "        \n",
    "        class_with_max = [classes[i] for i, count in enumerate(all_class_counts) if count == max_count]\n",
    "        class_with_min = [classes[i] for i, count in enumerate(all_class_counts) if count == min_count and count > 0]\n",
    "        \n",
    "        print(f\"Classe pi√π frequente: {', '.join(class_with_max)} ({max_count} oggetti)\")\n",
    "        print(f\"Classe meno frequente: {', '.join(class_with_min)} ({min_count} oggetti)\")\n",
    "        print(f\"Rapporto di sbilanciamento: {imbalance_ratio:.2f}:1\")\n",
    "        \n",
    "        # Suggerimenti bilanciamento\n",
    "        if imbalance_ratio > 10:\n",
    "            print(\"\\n‚ö†Ô∏è ATTENZIONE: Dataset fortemente sbilanciato!\")\n",
    "            print(\"Suggerimenti:\")\n",
    "            print(\"1. Considera tecniche di bilanciamento come oversampling o class weights\")\n",
    "            print(\"2. Per YOLO, puoi usare hyp.yaml con pesi delle classi per il training\")\n",
    "            print(\"3. Aggiungi pi√π immagini per le classi minoritarie\")\n",
    "        elif imbalance_ratio > 3:\n",
    "            print(\"\\n‚ö†Ô∏è Dataset moderatamente sbilanciato\")\n",
    "            print(\"Suggerimenti:\")\n",
    "            print(\"1. Considera tecniche di bilanciamento come class weights\")\n",
    "            print(\"2. Monitora attentamente precision e recall durante il training\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ Dataset relativamente bilanciato\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c46502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254db5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de03d6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b30a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
