{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cella 1: Installazione pacchetti base\n",
    "!pip install numpy pandas matplotlib seaborn pillow opencv-python\n",
    "\n",
    "# Cella 2: Installazione TensorFlow (versione CPU)\n",
    "!pip install tensorflow\n",
    "\n",
    "# Cella 3: Installazione OpenCV\n",
    "!pip install opencv-python\n",
    "\n",
    "# Cella 4: (Opzionale) Per accelerare operazioni su CPU\n",
    "!pip install tensorflow-addons\n",
    "\n",
    "# Cella 5: (Opzionale) Per visualizzazioni avanzate\n",
    "!pip install plotly\n",
    "\n",
    "# Cella 1: Installazione Ultralytics YOLO11\n",
    "!pip install ultralytics\n",
    "\n",
    "!pip install albumentations\n",
    "\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf544ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "import cv2\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a7b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# IMPORT LIBRERIE\n",
    "# ====================================\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import random\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib parameters\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "class YOLOFallDetectionTrainer:\n",
    "    def __init__(self, dataset_path, model_name='yolo11n.pt', img_size=640):\n",
    "        \"\"\"\n",
    "        Inizializza il trainer per YOLO11 Fall Detection\n",
    "        \n",
    "        Args:\n",
    "            dataset_path: Path alla directory del dataset in formato YOLO\n",
    "            model_name: Modello YOLO11 da usare (yolo11n.pt per CPU)\n",
    "            img_size: Dimensione immagini per training\n",
    "        \"\"\"\n",
    "        self.dataset_path = Path(dataset_path)\n",
    "        self.model_name = model_name\n",
    "        self.img_size = img_size\n",
    "        self.data_yaml_path = self.dataset_path / 'data.yaml'\n",
    "        \n",
    "        # Mapping delle classi\n",
    "        self.class_names = {0: 'not_fallen', 1: 'fallen'}\n",
    "        \n",
    "    def analyze_dataset(self):\n",
    "        \"\"\"Analisi completa del dataset YOLO\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"ANALISI DATASET YOLO - FALL DETECTION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Verifica struttura dataset (adattata alla tua struttura)\n",
    "        images_train_path = self.dataset_path / 'images' / 'train'\n",
    "        images_val_path = self.dataset_path / 'images' / 'val'\n",
    "        images_test_path = self.dataset_path / 'images' / 'test'\n",
    "        \n",
    "        labels_train_path = self.dataset_path / 'labels' / 'train'\n",
    "        labels_val_path = self.dataset_path / 'labels' / 'val'\n",
    "        labels_test_path = self.dataset_path / 'labels' / 'test'\n",
    "        \n",
    "        print(f\"\\n📁 Struttura Dataset:\")\n",
    "        print(f\"  • Images:\")\n",
    "        print(f\"    - Train: {'✅' if images_train_path.exists() else '❌'} {images_train_path}\")\n",
    "        print(f\"    - Val: {'✅' if images_val_path.exists() else '❌'} {images_val_path}\")\n",
    "        print(f\"    - Test: {'✅' if images_test_path.exists() else '❌'} {images_test_path}\")\n",
    "        print(f\"  • Labels:\")\n",
    "        print(f\"    - Train: {'✅' if labels_train_path.exists() else '❌'} {labels_train_path}\")\n",
    "        print(f\"    - Val: {'✅' if labels_val_path.exists() else '❌'} {labels_val_path}\")\n",
    "        print(f\"    - Test: {'✅' if labels_test_path.exists() else '❌'} {labels_test_path}\")\n",
    "        \n",
    "        # Analisi delle classi\n",
    "        class_distribution = self._analyze_class_distribution()\n",
    "        \n",
    "        # Analisi delle bounding box\n",
    "        bbox_stats = self._analyze_bounding_boxes()\n",
    "        \n",
    "        # Analisi qualità immagini\n",
    "        image_quality = self._analyze_image_quality()\n",
    "        \n",
    "        # Visualizzazioni\n",
    "        self._plot_dataset_analysis(class_distribution, bbox_stats, image_quality)\n",
    "        \n",
    "        return class_distribution, bbox_stats\n",
    "    \n",
    "    def _analyze_class_distribution(self):\n",
    "        \"\"\"Analizza la distribuzione delle classi nel dataset\"\"\"\n",
    "        distribution = {'train': {0: 0, 1: 0}, 'val': {0: 0, 1: 0}, 'test': {0: 0, 1: 0}}\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            labels_path = self.dataset_path / 'labels' / split\n",
    "            if labels_path.exists():\n",
    "                for label_file in labels_path.glob('*.txt'):\n",
    "                    with open(label_file, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                        for line in lines:\n",
    "                            if line.strip():\n",
    "                                class_id = int(line.split()[0])\n",
    "                                distribution[split][class_id] += 1\n",
    "        \n",
    "        print(f\"\\n📊 Distribuzione Classi:\")\n",
    "        for split, counts in distribution.items():\n",
    "            if sum(counts.values()) > 0:\n",
    "                print(f\"\\n  {split.upper()}:\")\n",
    "                total = sum(counts.values())\n",
    "                for class_id, count in counts.items():\n",
    "                    percentage = (count / total * 100) if total > 0 else 0\n",
    "                    print(f\"    • {self.class_names[class_id]}: {count} ({percentage:.1f}%)\")\n",
    "                \n",
    "                # Calcola imbalance ratio\n",
    "                if counts[0] > 0 and counts[1] > 0:\n",
    "                    imbalance = max(counts.values()) / min(counts.values())\n",
    "                    print(f\"    • Imbalance ratio: {imbalance:.2f}\")\n",
    "                    if imbalance > 2:\n",
    "                        print(f\"    ⚠️  Dataset sbilanciato! Considera data augmentation mirata\")\n",
    "        \n",
    "        return distribution\n",
    "    \n",
    "    def _analyze_bounding_boxes(self):\n",
    "        \"\"\"Analizza le dimensioni delle bounding box\"\"\"\n",
    "        bbox_stats = {'widths': [], 'heights': [], 'areas': [], 'aspects': []}\n",
    "        \n",
    "        labels_path = self.dataset_path / 'labels' / 'train'\n",
    "        images_path = self.dataset_path / 'images' / 'train'\n",
    "        \n",
    "        if labels_path.exists() and images_path.exists():\n",
    "            for label_file in list(labels_path.glob('*.txt'))[:100]:  # Sample 100 files\n",
    "                img_name = label_file.stem + '.jpg'\n",
    "                img_path = images_path / img_name\n",
    "                \n",
    "                if img_path.exists():\n",
    "                    # Leggi dimensioni immagine\n",
    "                    img = cv2.imread(str(img_path))\n",
    "                    if img is not None:\n",
    "                        h, w = img.shape[:2]\n",
    "                        \n",
    "                        # Leggi bounding box\n",
    "                        with open(label_file, 'r') as f:\n",
    "                            for line in f.readlines():\n",
    "                                if line.strip():\n",
    "                                    parts = line.strip().split()\n",
    "                                    if len(parts) >= 5:\n",
    "                                        _, x_center, y_center, width, height = map(float, parts[:5])\n",
    "                                        \n",
    "                                        # Converti da normalizzate a pixel\n",
    "                                        bbox_w = width * w\n",
    "                                        bbox_h = height * h\n",
    "                                        \n",
    "                                        bbox_stats['widths'].append(bbox_w)\n",
    "                                        bbox_stats['heights'].append(bbox_h)\n",
    "                                        bbox_stats['areas'].append(bbox_w * bbox_h)\n",
    "                                        bbox_stats['aspects'].append(bbox_w / bbox_h if bbox_h > 0 else 0)\n",
    "        \n",
    "        if bbox_stats['widths']:\n",
    "            print(f\"\\n📏 Statistiche Bounding Box:\")\n",
    "            print(f\"  • Larghezza media: {np.mean(bbox_stats['widths']):.1f}px\")\n",
    "            print(f\"  • Altezza media: {np.mean(bbox_stats['heights']):.1f}px\")\n",
    "            print(f\"  • Area media: {np.mean(bbox_stats['areas']):.1f}px²\")\n",
    "            print(f\"  • Aspect ratio medio: {np.mean(bbox_stats['aspects']):.2f}\")\n",
    "        \n",
    "        return bbox_stats\n",
    "    \n",
    "    def _analyze_image_quality(self):\n",
    "        \"\"\"Analizza la qualità delle immagini (luminosità, contrasto)\"\"\"\n",
    "        quality_stats = {'brightness': [], 'contrast': [], 'sharpness': []}\n",
    "        \n",
    "        images_path = self.dataset_path / 'images' / 'train'\n",
    "        if images_path.exists():\n",
    "            sample_images = list(images_path.glob('*.jpg'))[:50]  # Sample 50 images\n",
    "            \n",
    "            for img_path in sample_images:\n",
    "                img = cv2.imread(str(img_path))\n",
    "                if img is not None:\n",
    "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    # Brightness\n",
    "                    quality_stats['brightness'].append(np.mean(gray))\n",
    "                    \n",
    "                    # Contrast\n",
    "                    quality_stats['contrast'].append(np.std(gray))\n",
    "                    \n",
    "                    # Sharpness (usando Laplacian)\n",
    "                    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "                    quality_stats['sharpness'].append(laplacian.var())\n",
    "        \n",
    "        if quality_stats['brightness']:\n",
    "            print(f\"\\n🖼️ Qualità Immagini:\")\n",
    "            print(f\"  • Luminosità media: {np.mean(quality_stats['brightness']):.1f}\")\n",
    "            print(f\"  • Contrasto medio: {np.mean(quality_stats['contrast']):.1f}\")\n",
    "            print(f\"  • Nitidezza media: {np.mean(quality_stats['sharpness']):.1f}\")\n",
    "            \n",
    "            if np.mean(quality_stats['brightness']) < 50:\n",
    "                print(f\"  ⚠️  Immagini molto scure - applicherò augmentation luminosità\")\n",
    "            elif np.mean(quality_stats['brightness']) > 200:\n",
    "                print(f\"  ⚠️  Immagini molto chiare - attenzione a sovraesposizione\")\n",
    "        \n",
    "        return quality_stats\n",
    "    \n",
    "    def _plot_dataset_analysis(self, class_distribution, bbox_stats, image_quality):\n",
    "        \"\"\"Visualizza i risultati dell'analisi\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        fig.suptitle('Analisi Dataset YOLO - Fall Detection', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Distribuzione classi per split\n",
    "        ax = axes[0, 0]\n",
    "        splits = ['train', 'val', 'test']\n",
    "        not_fallen_counts = [class_distribution[split][0] for split in splits]\n",
    "        fallen_counts = [class_distribution[split][1] for split in splits]\n",
    "        \n",
    "        x = np.arange(len(splits))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, not_fallen_counts, width, label='not_fallen', color='#2ecc71')\n",
    "        ax.bar(x + width/2, fallen_counts, width, label='fallen', color='#e74c3c')\n",
    "        \n",
    "        ax.set_xlabel('Dataset Split')\n",
    "        ax.set_ylabel('Numero di Annotazioni')\n",
    "        ax.set_title('Distribuzione Classi per Split')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(splits)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Distribuzione dimensioni bbox\n",
    "        ax = axes[0, 1]\n",
    "        if bbox_stats['areas']:\n",
    "            ax.hist(bbox_stats['areas'], bins=30, color='#3498db', alpha=0.7, edgecolor='black')\n",
    "            ax.set_xlabel('Area Bounding Box (px²)')\n",
    "            ax.set_ylabel('Frequenza')\n",
    "            ax.set_title('Distribuzione Dimensioni Bounding Box')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Aspect ratio bbox\n",
    "        ax = axes[0, 2]\n",
    "        if bbox_stats['aspects']:\n",
    "            ax.hist(bbox_stats['aspects'], bins=30, color='#9b59b6', alpha=0.7, edgecolor='black')\n",
    "            ax.set_xlabel('Aspect Ratio (W/H)')\n",
    "            ax.set_ylabel('Frequenza')\n",
    "            ax.set_title('Distribuzione Aspect Ratio')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Luminosità immagini\n",
    "        ax = axes[1, 0]\n",
    "        if image_quality['brightness']:\n",
    "            ax.boxplot([image_quality['brightness']], labels=['Brightness'])\n",
    "            ax.set_ylabel('Valore (0-255)')\n",
    "            ax.set_title('Distribuzione Luminosità')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Contrasto immagini\n",
    "        ax = axes[1, 1]\n",
    "        if image_quality['contrast']:\n",
    "            ax.boxplot([image_quality['contrast']], labels=['Contrast'])\n",
    "            ax.set_ylabel('Deviazione Standard')\n",
    "            ax.set_title('Distribuzione Contrasto')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Sample di immagini con annotazioni\n",
    "        ax = axes[1, 2]\n",
    "        self._plot_sample_annotations(ax)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_sample_annotations(self, ax):\n",
    "        \"\"\"Mostra un esempio di immagine con annotazioni\"\"\"\n",
    "        images_path = self.dataset_path / 'images' / 'train'\n",
    "        labels_path = self.dataset_path / 'labels' / 'train'\n",
    "        \n",
    "        if images_path.exists() and labels_path.exists():\n",
    "            # Trova un'immagine con annotazioni\n",
    "            for img_file in images_path.glob('*.jpg'):\n",
    "                label_file = labels_path / (img_file.stem + '.txt')\n",
    "                if label_file.exists():\n",
    "                    img = cv2.imread(str(img_file))\n",
    "                    if img is not None:\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        h, w = img.shape[:2]\n",
    "                        \n",
    "                        # Leggi e disegna bbox\n",
    "                        with open(label_file, 'r') as f:\n",
    "                            for line in f.readlines():\n",
    "                                if line.strip():\n",
    "                                    parts = line.strip().split()\n",
    "                                    if len(parts) >= 5:\n",
    "                                        class_id, x_c, y_c, width, height = map(float, parts[:5])\n",
    "                                        \n",
    "                                        # Converti a coordinate pixel\n",
    "                                        x1 = int((x_c - width/2) * w)\n",
    "                                        y1 = int((y_c - height/2) * h)\n",
    "                                        x2 = int((x_c + width/2) * w)\n",
    "                                        y2 = int((y_c + height/2) * h)\n",
    "                                        \n",
    "                                        # Disegna bbox\n",
    "                                        color = (0, 255, 0) if class_id == 0 else (255, 0, 0)\n",
    "                                        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "                                        \n",
    "                                        # Aggiungi label\n",
    "                                        label = self.class_names[int(class_id)]\n",
    "                                        cv2.putText(img, label, (x1, y1-10), \n",
    "                                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                        \n",
    "                        ax.imshow(img)\n",
    "                        ax.set_title('Esempio Annotazioni')\n",
    "                        ax.axis('off')\n",
    "                        break\n",
    "    \n",
    "    def create_augmented_dataset(self, augmentation_factor=3, show_examples=True):\n",
    "        \"\"\"Crea un dataset augmentato con focus su occlusioni e variazioni luminosità\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CREAZIONE DATASET AUGMENTATO\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Definisci pipeline di augmentation\n",
    "        transform = A.Compose([\n",
    "            # Variazioni di luminosità estreme\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.4,\n",
    "                contrast_limit=0.4,\n",
    "                p=0.8\n",
    "            ),\n",
    "            \n",
    "            # Simulazione diverse condizioni di luce\n",
    "            A.OneOf([\n",
    "                A.RandomGamma(gamma_limit=(60, 140), p=1),\n",
    "                A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=30, p=1),\n",
    "                A.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=1),\n",
    "            ], p=0.7),\n",
    "            \n",
    "            # Occlusioni\n",
    "            A.OneOf([\n",
    "                A.CoarseDropout(\n",
    "                    max_holes=3,\n",
    "                    max_height=0.2,\n",
    "                    max_width=0.2,\n",
    "                    min_holes=1,\n",
    "                    fill_value=0,\n",
    "                    p=1\n",
    "                ),\n",
    "                A.GridDropout(\n",
    "                    ratio=0.3,\n",
    "                    unit_size_range=(10, 20),\n",
    "                    p=1\n",
    "                ),\n",
    "            ], p=0.6),\n",
    "            \n",
    "            # Blur e rumore\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=5, p=1),\n",
    "                A.GaussianBlur(blur_limit=5, p=1),\n",
    "                A.MedianBlur(blur_limit=5, p=1),\n",
    "            ], p=0.3),\n",
    "            \n",
    "            A.OneOf([\n",
    "                A.GaussNoise(var_limit=(10, 50), p=1),\n",
    "                A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=1),\n",
    "            ], p=0.3),\n",
    "            \n",
    "            # Trasformazioni geometriche\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.1,\n",
    "                scale_limit=0.2,\n",
    "                rotate_limit=15,\n",
    "                border_mode=cv2.BORDER_CONSTANT,\n",
    "                p=0.5\n",
    "            ),\n",
    "            \n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Perspective(scale=(0.05, 0.1), p=0.3),\n",
    "            \n",
    "        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "        \n",
    "        # Statistiche per analisi\n",
    "        stats = {\n",
    "            'original': {'images': 0, 'not_fallen': 0, 'fallen': 0},\n",
    "            'augmented': {'images': 0, 'not_fallen': 0, 'fallen': 0},\n",
    "            'failed': {'images': [], 'reasons': {}},\n",
    "            'problematic_bbox': []\n",
    "        }\n",
    "        \n",
    "        # Crea nuovo dataset path\n",
    "        parent_dir = self.dataset_path.parent\n",
    "        aug_dataset_path = parent_dir / 'augmented_yolo_dataset'\n",
    "        \n",
    "        # Crea struttura directory\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            (aug_dataset_path / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
    "            (aug_dataset_path / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Directory per esempi di augmentation\n",
    "        examples_dir = aug_dataset_path / 'augmentation_examples'\n",
    "        examples_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n📁 Creando nuovo dataset in: {aug_dataset_path}\")\n",
    "        \n",
    "        # Mostra esempi di augmentation prima di processare tutto\n",
    "        if show_examples:\n",
    "            self._show_augmentation_examples(transform, examples_dir)\n",
    "        \n",
    "        # Processa ogni split\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            orig_images = self.dataset_path / 'images' / split\n",
    "            orig_labels = self.dataset_path / 'labels' / split\n",
    "            \n",
    "            aug_images = aug_dataset_path / 'images' / split\n",
    "            aug_labels = aug_dataset_path / 'labels' / split\n",
    "            \n",
    "            if not orig_images.exists():\n",
    "                print(f\"⚠️  Skip {split}: directory non trovata\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n📁 Processando {split}...\")\n",
    "            \n",
    "            # Analizza e copia originali\n",
    "            for img_file in orig_images.glob('*.jpg'):\n",
    "                shutil.copy2(img_file, aug_images / img_file.name)\n",
    "                label_file = orig_labels / (img_file.stem + '.txt')\n",
    "                \n",
    "                if label_file.exists():\n",
    "                    shutil.copy2(label_file, aug_labels / label_file.name)\n",
    "                    \n",
    "                    # Conta classi originali\n",
    "                    with open(label_file, 'r') as f:\n",
    "                        for line in f:\n",
    "                            if line.strip():\n",
    "                                class_id = int(line.split()[0])\n",
    "                                if class_id == 0:\n",
    "                                    stats['original']['not_fallen'] += 1\n",
    "                                else:\n",
    "                                    stats['original']['fallen'] += 1\n",
    "                    \n",
    "                    stats['original']['images'] += 1\n",
    "            \n",
    "            # Applica augmentation solo al training set\n",
    "            if split == 'train':\n",
    "                print(f\"  • Applicando augmentation (fattore: {augmentation_factor}x)...\")\n",
    "                \n",
    "                successful_aug = 0\n",
    "                failed_aug = 0\n",
    "                \n",
    "                # Progress tracking\n",
    "                total_images = len(list(orig_images.glob('*.jpg')))\n",
    "                processed = 0\n",
    "                \n",
    "                for img_file in orig_images.glob('*.jpg'):\n",
    "                    processed += 1\n",
    "                    if processed % 100 == 0:\n",
    "                        print(f\"    Processate {processed}/{total_images} immagini...\")\n",
    "                    \n",
    "                    label_file = orig_labels / (img_file.stem + '.txt')\n",
    "                    \n",
    "                    if label_file.exists():\n",
    "                        # Leggi immagine e annotazioni\n",
    "                        image = cv2.imread(str(img_file))\n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        # Analizza bbox originali\n",
    "                        bboxes = []\n",
    "                        class_labels = []\n",
    "                        \n",
    "                        with open(label_file, 'r') as f:\n",
    "                            for line in f.readlines():\n",
    "                                if line.strip():\n",
    "                                    parts = line.strip().split()\n",
    "                                    if len(parts) >= 5:\n",
    "                                        class_id = int(parts[0])\n",
    "                                        bbox = list(map(float, parts[1:5]))\n",
    "                                        \n",
    "                                        # Check bbox problematiche\n",
    "                                        x, y, w, h = bbox\n",
    "                                        if (x - w/2 < 0.001 or x + w/2 > 0.999 or \n",
    "                                            y - h/2 < 0.001 or y + h/2 > 0.999):\n",
    "                                            stats['problematic_bbox'].append({\n",
    "                                                'file': img_file.name,\n",
    "                                                'bbox': bbox,\n",
    "                                                'issue': 'near_border'\n",
    "                                            })\n",
    "                                        \n",
    "                                        bboxes.append(bbox)\n",
    "                                        class_labels.append(class_id)\n",
    "                        \n",
    "                        # Applica augmentation multiple volte\n",
    "                        aug_success_count = 0\n",
    "                        for i in range(augmentation_factor):\n",
    "                            try:\n",
    "                                # Pre-processa bbox vicine ai bordi\n",
    "                                safe_bboxes = []\n",
    "                                for bbox in bboxes:\n",
    "                                    x, y, w, h = bbox\n",
    "                                    # Porta le bbox leggermente all'interno\n",
    "                                    x = np.clip(x, w/2 + 0.001, 1 - w/2 - 0.001)\n",
    "                                    y = np.clip(y, h/2 + 0.001, 1 - h/2 - 0.001)\n",
    "                                    safe_bboxes.append([x, y, w, h])\n",
    "                                \n",
    "                                # Applica trasformazioni\n",
    "                                transformed = transform(image=image, bboxes=safe_bboxes, class_labels=class_labels)\n",
    "                                \n",
    "                                # Valida e salva solo se ci sono bbox valide\n",
    "                                if transformed['bboxes']:\n",
    "                                    # Salva immagine\n",
    "                                    aug_img_name = f\"{img_file.stem}_aug_{i}.jpg\"\n",
    "                                    aug_img_path = aug_images / aug_img_name\n",
    "                                    aug_image = cv2.cvtColor(transformed['image'], cv2.COLOR_RGB2BGR)\n",
    "                                    cv2.imwrite(str(aug_img_path), aug_image)\n",
    "                                    \n",
    "                                    # Salva annotazioni\n",
    "                                    aug_label_path = aug_labels / f\"{img_file.stem}_aug_{i}.txt\"\n",
    "                                    with open(aug_label_path, 'w') as f:\n",
    "                                        for bbox, class_id in zip(transformed['bboxes'], transformed['class_labels']):\n",
    "                                            # Validazione finale\n",
    "                                            x, y, w, h = bbox\n",
    "                                            if 0 < x < 1 and 0 < y < 1 and 0 < w < 1 and 0 < h < 1:\n",
    "                                                f.write(f\"{class_id} {x} {y} {w} {h}\\n\")\n",
    "                                                \n",
    "                                                # Conta classi augmentate\n",
    "                                                if class_id == 0:\n",
    "                                                    stats['augmented']['not_fallen'] += 1\n",
    "                                                else:\n",
    "                                                    stats['augmented']['fallen'] += 1\n",
    "                                    \n",
    "                                    aug_success_count += 1\n",
    "                                    stats['augmented']['images'] += 1\n",
    "                                    \n",
    "                            except Exception as e:\n",
    "                                error_type = type(e).__name__\n",
    "                                if error_type not in stats['failed']['reasons']:\n",
    "                                    stats['failed']['reasons'][error_type] = 0\n",
    "                                stats['failed']['reasons'][error_type] += 1\n",
    "                                \n",
    "                                if len(stats['failed']['images']) < 10:  # Salva solo primi 10\n",
    "                                    stats['failed']['images'].append({\n",
    "                                        'file': img_file.name,\n",
    "                                        'error': str(e)\n",
    "                                    })\n",
    "                        \n",
    "                        if aug_success_count == augmentation_factor:\n",
    "                            successful_aug += 1\n",
    "                        else:\n",
    "                            failed_aug += 1\n",
    "                \n",
    "                print(f\"\\n  ✅ Augmentation completata:\")\n",
    "                print(f\"    • Immagini processate con successo: {successful_aug}\")\n",
    "                print(f\"    • Immagini con errori parziali: {failed_aug}\")\n",
    "        \n",
    "        # Analisi finale e report\n",
    "        self._generate_augmentation_report(stats, aug_dataset_path)\n",
    "        \n",
    "        # Crea data.yaml\n",
    "        data_config = {\n",
    "            'path': str(aug_dataset_path.absolute()),\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/val',\n",
    "            'test': 'images/test',\n",
    "            'names': {\n",
    "                0: 'not_fallen',\n",
    "                1: 'fallen'\n",
    "            },\n",
    "            'nc': 2\n",
    "        }\n",
    "        \n",
    "        with open(aug_dataset_path / 'data.yaml', 'w') as f:\n",
    "            yaml.dump(data_config, f, default_flow_style=False)\n",
    "        \n",
    "        # Aggiorna path\n",
    "        self.dataset_path = aug_dataset_path\n",
    "        self.data_yaml_path = aug_dataset_path / 'data.yaml'\n",
    "        \n",
    "        return aug_dataset_path\n",
    "\n",
    "    def _show_augmentation_examples(self, transform, examples_dir):\n",
    "        \"\"\"Mostra esempi di augmentation applicata\"\"\"\n",
    "        print(\"\\n🎨 ESEMPI DI AUGMENTATION\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        # Seleziona immagini campione\n",
    "        train_images = self.dataset_path / 'images' / 'train'\n",
    "        sample_images = list(train_images.glob('*.jpg'))[:3]  # 3 esempi\n",
    "        \n",
    "        fig, axes = plt.subplots(len(sample_images), 5, figsize=(20, 4*len(sample_images)))\n",
    "        if len(sample_images) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        augmentation_types = [\n",
    "            \"Originale\",\n",
    "            \"Brightness/Contrast\", \n",
    "            \"Occlusioni\",\n",
    "            \"Blur/Noise\",\n",
    "            \"Geometrica\"\n",
    "        ]\n",
    "        \n",
    "        for idx, img_path in enumerate(sample_images):\n",
    "            # Carica immagine e label\n",
    "            image = cv2.imread(str(img_path))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            h, w = image.shape[:2]\n",
    "            \n",
    "            label_path = self.dataset_path / 'labels' / 'train' / (img_path.stem + '.txt')\n",
    "            bboxes = []\n",
    "            class_labels = []\n",
    "            \n",
    "            if label_path.exists():\n",
    "                with open(label_path, 'r') as f:\n",
    "                    for line in f:\n",
    "                        if line.strip():\n",
    "                            parts = line.strip().split()\n",
    "                            class_id = int(parts[0])\n",
    "                            bbox = list(map(float, parts[1:5]))\n",
    "                            bboxes.append(bbox)\n",
    "                            class_labels.append(class_id)\n",
    "            \n",
    "            # Mostra originale\n",
    "            ax = axes[idx, 0]\n",
    "            img_show = image.copy()\n",
    "            \n",
    "            # Disegna bbox\n",
    "            for bbox, class_id in zip(bboxes, class_labels):\n",
    "                x_c, y_c, width, height = bbox\n",
    "                x1 = int((x_c - width/2) * w)\n",
    "                y1 = int((y_c - height/2) * h)\n",
    "                x2 = int((x_c + width/2) * w)\n",
    "                y2 = int((y_c + height/2) * h)\n",
    "                \n",
    "                color = (0, 255, 0) if class_id == 0 else (255, 0, 0)\n",
    "                cv2.rectangle(img_show, (x1, y1), (x2, y2), color, 2)\n",
    "                label = 'not_fallen' if class_id == 0 else 'fallen'\n",
    "                cv2.putText(img_show, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            \n",
    "            ax.imshow(img_show)\n",
    "            ax.set_title(f\"{augmentation_types[0]}\\n{img_path.name}\", fontsize=10)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Applica e mostra diverse augmentation\n",
    "            for aug_idx in range(1, 5):\n",
    "                try:\n",
    "                    # Applica transform\n",
    "                    safe_bboxes = [[np.clip(x, w/2+0.01, 1-w/2-0.01), \n",
    "                                np.clip(y, h/2+0.01, 1-h/2-0.01), w, h] \n",
    "                                for x, y, w, h in bboxes]\n",
    "                    \n",
    "                    transformed = transform(image=image, bboxes=safe_bboxes, class_labels=class_labels)\n",
    "                    \n",
    "                    # Visualizza\n",
    "                    ax = axes[idx, aug_idx]\n",
    "                    aug_img = transformed['image'].copy()\n",
    "                    \n",
    "                    # Disegna bbox trasformate\n",
    "                    for bbox, class_id in zip(transformed['bboxes'], transformed['class_labels']):\n",
    "                        x_c, y_c, width, height = bbox\n",
    "                        x1 = int((x_c - width/2) * w)\n",
    "                        y1 = int((y_c - height/2) * h)\n",
    "                        x2 = int((x_c + width/2) * w)\n",
    "                        y2 = int((y_c + height/2) * h)\n",
    "                        \n",
    "                        color = (0, 255, 0) if class_id == 0 else (255, 0, 0)\n",
    "                        cv2.rectangle(aug_img, (x1, y1), (x2, y2), color, 2)\n",
    "                    \n",
    "                    ax.imshow(aug_img)\n",
    "                    ax.set_title(augmentation_types[aug_idx], fontsize=10)\n",
    "                    ax.axis('off')\n",
    "                    \n",
    "                    # Salva esempio\n",
    "                    example_name = f\"example_{idx}_{augmentation_types[aug_idx].replace('/', '_')}.jpg\"\n",
    "                    cv2.imwrite(str(examples_dir / example_name), \n",
    "                            cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    ax = axes[idx, aug_idx]\n",
    "                    ax.text(0.5, 0.5, f\"Errore:\\n{type(e).__name__}\", \n",
    "                        ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.axis('off')\n",
    "        \n",
    "        plt.suptitle(\"Esempi di Data Augmentation Applicata\", fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n📌 AUGMENTATION APPLICATE:\")\n",
    "        print(\"  • Brightness/Contrast: ±40% variazione\")\n",
    "        print(\"  • Gamma/HSV/RGB shift: Simula diverse condizioni luce\")\n",
    "        print(\"  • Occlusioni: Rettangoli casuali, grid dropout\")\n",
    "        print(\"  • Blur: Motion, Gaussian, Median\")\n",
    "        print(\"  • Rumore: Gaussian, ISO noise\")\n",
    "        print(\"  • Geometriche: Rotazione ±15°, shift, scale, flip\")\n",
    "\n",
    "    def _generate_augmentation_report(self, stats, aug_dataset_path):\n",
    "        \"\"\"Genera report dettagliato dell'augmentation\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"📊 REPORT AUGMENTATION DETTAGLIATO\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Bilanciamento dataset originale\n",
    "        print(\"\\n1️⃣ DATASET ORIGINALE:\")\n",
    "        print(f\"  • Immagini totali: {stats['original']['images']}\")\n",
    "        print(f\"  • Not_fallen: {stats['original']['not_fallen']}\")\n",
    "        print(f\"  • Fallen: {stats['original']['fallen']}\")\n",
    "        \n",
    "        if stats['original']['not_fallen'] + stats['original']['fallen'] > 0:\n",
    "            ratio_orig = stats['original']['not_fallen'] / (stats['original']['fallen'] + 1e-6)\n",
    "            print(f\"  • Ratio not_fallen/fallen: {ratio_orig:.2f}\")\n",
    "        \n",
    "        # Bilanciamento dataset augmentato\n",
    "        print(\"\\n2️⃣ DATASET AUGMENTATO:\")\n",
    "        total_aug_images = len(list((aug_dataset_path / 'images' / 'train').glob('*.jpg')))\n",
    "        print(f\"  • Immagini totali training: {total_aug_images}\")\n",
    "        print(f\"  • Immagini generate: {stats['augmented']['images']}\")\n",
    "        print(f\"  • Not_fallen augmentate: {stats['augmented']['not_fallen']}\")\n",
    "        print(f\"  • Fallen augmentate: {stats['augmented']['fallen']}\")\n",
    "        \n",
    "        # Bilanciamento finale\n",
    "        total_not_fallen = stats['original']['not_fallen'] + stats['augmented']['not_fallen']\n",
    "        total_fallen = stats['original']['fallen'] + stats['augmented']['fallen']\n",
    "        \n",
    "        print(\"\\n3️⃣ BILANCIAMENTO FINALE:\")\n",
    "        print(f\"  • Not_fallen totali: {total_not_fallen}\")\n",
    "        print(f\"  • Fallen totali: {total_fallen}\")\n",
    "        print(f\"  • Ratio finale: {total_not_fallen / (total_fallen + 1e-6):.2f}\")\n",
    "        \n",
    "        # Analisi errori\n",
    "        print(\"\\n4️⃣ ANALISI ERRORI AUGMENTATION:\")\n",
    "        total_failed = sum(stats['failed']['reasons'].values())\n",
    "        print(f\"  • Totale errori: {total_failed}\")\n",
    "        \n",
    "        if stats['failed']['reasons']:\n",
    "            print(\"  • Tipi di errore:\")\n",
    "            for error_type, count in stats['failed']['reasons'].items():\n",
    "                print(f\"    - {error_type}: {count}\")\n",
    "        \n",
    "        # Bbox problematiche\n",
    "        if stats['problematic_bbox']:\n",
    "            print(f\"\\n5️⃣ BBOX PROBLEMATICHE (vicine ai bordi):\")\n",
    "            print(f\"  • Totale: {len(stats['problematic_bbox'])}\")\n",
    "            print(\"  • Esempi:\")\n",
    "            for item in stats['problematic_bbox'][:3]:\n",
    "                print(f\"    - {item['file']}: bbox {item['bbox']}\")\n",
    "        \n",
    "        # Raccomandazioni\n",
    "        print(\"\\n💡 RACCOMANDAZIONI:\")\n",
    "        \n",
    "        if total_failed > stats['original']['images'] * 0.1:\n",
    "            print(\"  ⚠️ Alto tasso di errori (>10%). Considera di:\")\n",
    "            print(\"    - Verificare le annotazioni originali\")\n",
    "            print(\"    - Ridurre l'intensità delle augmentation\")\n",
    "        \n",
    "        if len(stats['problematic_bbox']) > stats['original']['images'] * 0.05:\n",
    "            print(\"  ⚠️ Molte bbox vicine ai bordi. Considera di:\")\n",
    "            print(\"    - Rivedere le annotazioni originali\")\n",
    "            print(\"    - Applicare padding alle immagini\")\n",
    "        \n",
    "        ratio_final = total_not_fallen / (total_fallen + 1e-6)\n",
    "        if ratio_final > 1.5 or ratio_final < 0.67:\n",
    "            print(\"  ⚠️ Dataset ancora sbilanciato. Considera di:\")\n",
    "            print(\"    - Applicare augmentation selettiva per classe minoritaria\")\n",
    "            print(\"    - Usare class weights durante il training\")\n",
    "        else:\n",
    "            print(\"  ✅ Bilanciamento ottimale raggiunto!\")\n",
    "        \n",
    "        # Salva report su file\n",
    "        report_path = aug_dataset_path / 'augmentation_report.txt'\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(\"AUGMENTATION REPORT\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "            f.write(f\"Data: {pd.Timestamp.now()}\\n\\n\")\n",
    "            f.write(f\"Dataset originale: {stats['original']}\\n\")\n",
    "            f.write(f\"Augmentation stats: {stats['augmented']}\\n\")\n",
    "            f.write(f\"Errori: {stats['failed']['reasons']}\\n\")\n",
    "            f.write(f\"Bbox problematiche: {len(stats['problematic_bbox'])}\\n\")\n",
    "        \n",
    "        print(f\"\\n📄 Report salvato in: {report_path}\")\n",
    "    \n",
    "    def _update_data_yaml(self, use_augmented=False):\n",
    "        \"\"\"Aggiorna o crea il file data.yaml per YOLO\"\"\"\n",
    "        \n",
    "        # Paths relativi per la tua struttura\n",
    "        if use_augmented:\n",
    "            train_images = 'images/train_augmented'\n",
    "            train_labels = 'labels/train_augmented'\n",
    "        else:\n",
    "            train_images = 'images/train'\n",
    "            train_labels = 'labels/train'\n",
    "        \n",
    "        data_config = {\n",
    "            'path': str(self.dataset_path.absolute()),\n",
    "            'train': train_images,\n",
    "            'val': 'images/val',\n",
    "            'test': 'images/test',\n",
    "            'names': {\n",
    "                0: 'not_fallen',\n",
    "                1: 'fallen'\n",
    "            },\n",
    "            'nc': 2\n",
    "        }\n",
    "        \n",
    "        with open(self.data_yaml_path, 'w') as f:\n",
    "            yaml.dump(data_config, f, default_flow_style=False)\n",
    "        \n",
    "        print(f\"\\n✅ File data.yaml aggiornato: {self.data_yaml_path}\")\n",
    "        \n",
    "    def validate_augmented_dataset(self):\n",
    "        \"\"\"Valida il dataset augmentato prima del training\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"VALIDAZIONE DATASET AUGMENTATO\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        issues = {'missing_labels': [], 'invalid_bbox': [], 'empty_labels': []}\n",
    "        stats = {'train': {}, 'val': {}, 'test': {}}\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            print(f\"\\n🔍 Verificando {split}...\")\n",
    "            \n",
    "            images_path = self.dataset_path / 'images' / split\n",
    "            labels_path = self.dataset_path / 'labels' / split\n",
    "            \n",
    "            image_files = list(images_path.glob('*.jpg'))\n",
    "            label_files = list(labels_path.glob('*.txt'))\n",
    "            \n",
    "            stats[split] = {\n",
    "                'images': len(image_files),\n",
    "                'labels': len(label_files),\n",
    "                'class_distribution': {0: 0, 1: 0}\n",
    "            }\n",
    "            \n",
    "            # Check 1: Corrispondenza immagini-labels\n",
    "            for img_file in image_files:\n",
    "                label_file = labels_path / (img_file.stem + '.txt')\n",
    "                if not label_file.exists():\n",
    "                    issues['missing_labels'].append(str(img_file))\n",
    "            \n",
    "            # Check 2: Validità bbox e distribuzione classi\n",
    "            for label_file in label_files:\n",
    "                with open(label_file, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    \n",
    "                if not lines:\n",
    "                    issues['empty_labels'].append(str(label_file))\n",
    "                    continue\n",
    "                    \n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        class_id = int(parts[0])\n",
    "                        x, y, w, h = map(float, parts[1:5])\n",
    "                        \n",
    "                        # Verifica range\n",
    "                        if not (0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1):\n",
    "                            issues['invalid_bbox'].append(f\"{label_file.name}: {line.strip()}\")\n",
    "                        \n",
    "                        # Verifica che bbox non esca dai bordi\n",
    "                        if (x - w/2 < 0 or x + w/2 > 1 or y - h/2 < 0 or y + h/2 > 1):\n",
    "                            issues['invalid_bbox'].append(f\"{label_file.name}: bbox fuori dai bordi\")\n",
    "                        \n",
    "                        stats[split]['class_distribution'][class_id] += 1\n",
    "        \n",
    "        # Report\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"📊 REPORT VALIDAZIONE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Statistiche per split\n",
    "        for split, data in stats.items():\n",
    "            print(f\"\\n{split.upper()}:\")\n",
    "            print(f\"  • Immagini: {data['images']}\")\n",
    "            print(f\"  • Labels: {data['labels']}\")\n",
    "            print(f\"  • Not_fallen: {data['class_distribution'][0]}\")\n",
    "            print(f\"  • Fallen: {data['class_distribution'][1]}\")\n",
    "            \n",
    "            if data['images'] != data['labels']:\n",
    "                print(f\"  ⚠️ ATTENZIONE: Mismatch immagini/labels!\")\n",
    "        \n",
    "        # Issues trovate\n",
    "        print(f\"\\n🚨 PROBLEMI TROVATI:\")\n",
    "        print(f\"  • Labels mancanti: {len(issues['missing_labels'])}\")\n",
    "        print(f\"  • Labels vuote: {len(issues['empty_labels'])}\")\n",
    "        print(f\"  • Bbox invalide: {len(issues['invalid_bbox'])}\")\n",
    "        \n",
    "        if issues['invalid_bbox']:\n",
    "            print(f\"\\n  Esempi di bbox invalide (max 5):\")\n",
    "            for issue in issues['invalid_bbox'][:5]:\n",
    "                print(f\"    - {issue}\")\n",
    "        \n",
    "        # Raccomandazioni\n",
    "        print(f\"\\n💡 RACCOMANDAZIONI:\")\n",
    "        if len(issues['missing_labels']) > 0:\n",
    "            print(f\"  ⚠️ Rimuovi {len(issues['missing_labels'])} immagini senza label\")\n",
    "        if len(issues['invalid_bbox']) > 0:\n",
    "            print(f\"  ⚠️ Ci sono {len(issues['invalid_bbox'])} bbox problematiche\")\n",
    "        \n",
    "        total_issues = sum(len(v) for v in issues.values())\n",
    "        if total_issues == 0:\n",
    "            print(\"  ✅ Dataset pronto per il training!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"  ⚠️ Trovati {total_issues} problemi. Vuoi procedere comunque?\")\n",
    "            return False\n",
    "\n",
    "    # Aggiungi anche questa funzione per pulire il dataset se necessario\n",
    "    def clean_dataset(self):\n",
    "        \"\"\"Rimuove immagini senza labels corrispondenti\"\"\"\n",
    "        print(\"\\n🧹 Pulizia dataset...\")\n",
    "        \n",
    "        removed_count = 0\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            images_path = self.dataset_path / 'images' / split\n",
    "            labels_path = self.dataset_path / 'labels' / split\n",
    "            \n",
    "            for img_file in images_path.glob('*.jpg'):\n",
    "                label_file = labels_path / (img_file.stem + '.txt')\n",
    "                if not label_file.exists():\n",
    "                    img_file.unlink()  # Rimuovi immagine\n",
    "                    removed_count += 1\n",
    "        \n",
    "        print(f\"✅ Rimosse {removed_count} immagini senza label\")\n",
    "    \n",
    "    def train_model(self, epochs=100, patience=20, batch_size=16):\n",
    "        \"\"\"Training del modello YOLO11 con configurazioni ottimizzate per CPU\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"TRAINING YOLO11 - FALL DETECTION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Carica modello\n",
    "        print(f\"\\n📦 Caricando modello: {self.model_name}\")\n",
    "        model = YOLO(self.model_name)\n",
    "        \n",
    "        # Configurazione training ottimizzata per CPU\n",
    "        training_args = {\n",
    "            'data': str(self.data_yaml_path),\n",
    "            'epochs': epochs,\n",
    "            'patience': patience,\n",
    "            'batch': batch_size,\n",
    "            'imgsz': self.img_size,\n",
    "            \n",
    "            # Ottimizzazioni CPU\n",
    "            'device': 'cpu',\n",
    "            'workers': 4,  # Numero di worker per data loading\n",
    "            'cache': True,  # Cache immagini in RAM per velocizzare\n",
    "            \n",
    "            # Augmentation aggiuntive YOLO\n",
    "            'augment': True,\n",
    "            'degrees': 15,  # Rotazione\n",
    "            'translate': 0.1,  # Traslazione\n",
    "            'scale': 0.2,  # Scaling\n",
    "            'shear': 5,  # Shear\n",
    "            'perspective': 0.0005,  # Prospettiva\n",
    "            'flipud': 0.0,  # No flip verticale per cadute\n",
    "            'fliplr': 0.5,  # Flip orizzontale\n",
    "            'mosaic': 0.7,  # Mosaic augmentation\n",
    "            'mixup': 0.3,  # Mixup augmentation\n",
    "            \n",
    "            # Variazioni colore/luminosità\n",
    "            'hsv_h': 0.015,  # Hue\n",
    "            'hsv_s': 0.7,  # Saturation\n",
    "            'hsv_v': 0.4,  # Value (brightness)\n",
    "            \n",
    "            # Altre configurazioni\n",
    "            'cls': 1.0,  # Peso loss classificazione\n",
    "            'box': 7.5,  # Peso loss bounding box\n",
    "            'dfl': 1.5,  # Peso Distribution Focal Loss\n",
    "            \n",
    "            # Optimizer\n",
    "            'optimizer': 'Adam',\n",
    "            'lr0': 0.001,  # Learning rate iniziale\n",
    "            'lrf': 0.01,  # Learning rate finale\n",
    "            'momentum': 0.937,\n",
    "            'weight_decay': 0.0005,\n",
    "            'warmup_epochs': 3.0,\n",
    "            'warmup_momentum': 0.8,\n",
    "            'warmup_bias_lr': 0.1,\n",
    "            \n",
    "            # Salvataggio\n",
    "            'save': True,\n",
    "            'save_period': 5,\n",
    "            'val': True,\n",
    "            'plots': True,\n",
    "            'verbose': True,\n",
    "            \n",
    "            # Nome progetto\n",
    "            'project': 'fall_detection',\n",
    "            'name': 'yolo11_cpu_optimized',\n",
    "            'exist_ok': True\n",
    "        }\n",
    "        \n",
    "        print(\"\\n⚙️ Configurazione Training:\")\n",
    "        print(f\"  • Modello: {self.model_name}\")\n",
    "        print(f\"  • Immagini: {self.img_size}x{self.img_size}\")\n",
    "        print(f\"  • Batch size: {batch_size}\")\n",
    "        print(f\"  • Epochs: {epochs}\")\n",
    "        print(f\"  • Device: CPU (ottimizzato)\")\n",
    "        print(f\"  • Augmentation: Avanzata per occlusioni e luminosità\")\n",
    "        \n",
    "        # Avvia training\n",
    "        print(\"\\n🚀 Avvio training...\")\n",
    "        results = model.train(**training_args)\n",
    "        \n",
    "        # Valutazione\n",
    "        print(\"\\n📊 Valutazione modello...\")\n",
    "        metrics = model.val()\n",
    "        \n",
    "        # Salva modello migliore\n",
    "        best_model_path = Path('fall_detection/yolo11_cpu_optimized/weights/best.pt')\n",
    "        if best_model_path.exists():\n",
    "            shutil.copy2(best_model_path, 'best_fall_detection_yolo11.pt')\n",
    "            print(f\"\\n✅ Modello migliore salvato: best_fall_detection_yolo11.pt\")\n",
    "        \n",
    "        # Visualizza risultati\n",
    "        self._plot_training_results()\n",
    "        \n",
    "        return model, results, metrics\n",
    "    \n",
    "    def _plot_training_results(self):\n",
    "        \"\"\"Visualizza i risultati del training\"\"\"\n",
    "        results_path = Path('fall_detection/yolo11_cpu_optimized')\n",
    "        \n",
    "        # Cerca file risultati\n",
    "        results_csv = results_path / 'results.csv'\n",
    "        \n",
    "        if results_csv.exists():\n",
    "            # Leggi risultati\n",
    "            df = pd.read_csv(results_csv)\n",
    "            df.columns = [col.strip() for col in df.columns]\n",
    "            \n",
    "            # Crea grafici\n",
    "            fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "            fig.suptitle('Risultati Training YOLO11 - Fall Detection', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Box Loss\n",
    "            ax = axes[0, 0]\n",
    "            if 'train/box_loss' in df.columns:\n",
    "                ax.plot(df.index, df['train/box_loss'], label='Train', linewidth=2)\n",
    "                ax.plot(df.index, df['val/box_loss'], label='Val', linewidth=2)\n",
    "                ax.set_title('Box Loss')\n",
    "                ax.set_xlabel('Epoch')\n",
    "                ax.set_ylabel('Loss')\n",
    "                ax.legend()\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Class Loss\n",
    "            ax = axes[0, 1]\n",
    "            if 'train/cls_loss' in df.columns:\n",
    "                ax.plot(df.index, df['train/cls_loss'], label='Train', linewidth=2)\n",
    "                ax.plot(df.index, df['val/cls_loss'], label='Val', linewidth=2)\n",
    "                ax.set_title('Classification Loss')\n",
    "                ax.set_xlabel('Epoch')\n",
    "                ax.set_ylabel('Loss')\n",
    "                ax.legend()\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # DFL Loss\n",
    "            ax = axes[0, 2]\n",
    "            if 'train/dfl_loss' in df.columns:\n",
    "                ax.plot(df.index, df['train/dfl_loss'], label='Train', linewidth=2)\n",
    "                ax.plot(df.index, df['val/dfl_loss'], label='Val', linewidth=2)\n",
    "                ax.set_title('DFL Loss')\n",
    "                ax.set_xlabel('Epoch')\n",
    "                ax.set_ylabel('Loss')\n",
    "                ax.legend()\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Precision\n",
    "            ax = axes[1, 0]\n",
    "            if 'metrics/precision(B)' in df.columns:\n",
    "                ax.plot(df.index, df['metrics/precision(B)'], label='Precision', linewidth=2, color='green')\n",
    "                ax.set_title('Precision')\n",
    "                ax.set_xlabel('Epoch')\n",
    "                ax.set_ylabel('Score')\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Recall\n",
    "            ax = axes[1, 1]\n",
    "            if 'metrics/recall(B)' in df.columns:\n",
    "                ax.plot(df.index, df['metrics/recall(B)'], label='Recall', linewidth=2, color='blue')\n",
    "                ax.set_title('Recall')\n",
    "                ax.set_xlabel('Epoch')\n",
    "                ax.set_ylabel('Score')\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # mAP\n",
    "            ax = axes[1, 2]\n",
    "            if 'metrics/mAP50(B)' in df.columns:\n",
    "                ax.plot(df.index, df['metrics/mAP50(B)'], label='mAP@50', linewidth=2, color='red')\n",
    "                ax.plot(df.index, df['metrics/mAP50-95(B)'], label='mAP@50-95', linewidth=2, color='orange')\n",
    "                ax.set_title('Mean Average Precision')\n",
    "                ax.set_xlabel('Epoch')\n",
    "                ax.set_ylabel('mAP')\n",
    "                ax.legend()\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Stampa metriche finali\n",
    "            print(\"\\n📊 METRICHE FINALI:\")\n",
    "            final_metrics = df.iloc[-1]\n",
    "            \n",
    "            if 'metrics/precision(B)' in df.columns:\n",
    "                print(f\"  • Precision: {final_metrics['metrics/precision(B)']:.3f}\")\n",
    "            if 'metrics/recall(B)' in df.columns:\n",
    "                print(f\"  • Recall: {final_metrics['metrics/recall(B)']:.3f}\")\n",
    "            if 'metrics/mAP50(B)' in df.columns:\n",
    "                print(f\"  • mAP@50: {final_metrics['metrics/mAP50(B)']:.3f}\")\n",
    "            if 'metrics/mAP50-95(B)' in df.columns:\n",
    "                print(f\"  • mAP@50-95: {final_metrics['metrics/mAP50-95(B)']:.3f}\")\n",
    "    \n",
    "    def test_model(self, model_path='best_fall_detection_yolo11.pt'):\n",
    "        \"\"\"Test del modello su test set\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"TEST MODELLO YOLO11\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Carica modello\n",
    "        model = YOLO(model_path)\n",
    "        \n",
    "        # Test su immagini nella cartella test\n",
    "        test_images_path = self.dataset_path / 'images' / 'test'\n",
    "        \n",
    "        if test_images_path.exists():\n",
    "            results = model.val(\n",
    "                data=str(self.data_yaml_path),\n",
    "                split='test',\n",
    "                save_json=True,\n",
    "                save_txt=True,\n",
    "                plots=True,\n",
    "                verbose=True\n",
    "            )\n",
    "        \n",
    "        # Analisi per classe\n",
    "        print(\"\\n📊 PERFORMANCE PER CLASSE:\")\n",
    "        \n",
    "        # Estrai metriche per classe\n",
    "        if hasattr(results, 'box'):\n",
    "            # Per YOLO11, le metriche sono accessibili diversamente\n",
    "            if hasattr(results.box, 'ap_class_index'):\n",
    "                # Metriche per classe disponibili\n",
    "                for idx, class_id in enumerate(results.names.keys()):\n",
    "                    class_name = self.class_names[class_id]\n",
    "                    print(f\"\\n  {class_name}:\")\n",
    "                    \n",
    "                    # Prova ad accedere alle metriche specifiche della classe\n",
    "                    try:\n",
    "                        if hasattr(results.box, 'p'):\n",
    "                            print(f\"    • Precision: {results.box.p[idx]:.3f}\")\n",
    "                        if hasattr(results.box, 'r'):\n",
    "                            print(f\"    • Recall: {results.box.r[idx]:.3f}\")\n",
    "                        if hasattr(results.box, 'ap50'):\n",
    "                            print(f\"    • mAP@50: {results.box.ap50[idx]:.3f}\")\n",
    "                        if hasattr(results.box, 'ap'):\n",
    "                            print(f\"    • mAP@50-95: {results.box.ap[idx]:.3f}\")\n",
    "                    except:\n",
    "                        print(f\"    • Metriche dettagliate non disponibili\")\n",
    "            else:\n",
    "                # Stampa metriche generali se non ci sono metriche per classe\n",
    "                print(\"\\n  Metriche generali:\")\n",
    "                print(f\"    • mAP@50: {results.box.map50:.3f}\")\n",
    "                print(f\"    • mAP@50-95: {results.box.map:.3f}\")\n",
    "                print(f\"    • Precision media: {results.box.mp:.3f}\")\n",
    "                print(f\"    • Recall medio: {results.box.mr:.3f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def predict_image(self, image_path, model_path='best_fall_detection_yolo11.pt', \n",
    "                     conf_threshold=0.25, save_result=True):\n",
    "        \"\"\"Predizione su singola immagine\"\"\"\n",
    "        \n",
    "        # Carica modello\n",
    "        model = YOLO(model_path)\n",
    "        \n",
    "        # Predizione\n",
    "        results = model.predict(\n",
    "            source=image_path,\n",
    "            conf=conf_threshold,\n",
    "            save=save_result,\n",
    "            save_txt=True,\n",
    "            show_labels=True,\n",
    "            show_conf=True\n",
    "        )\n",
    "        \n",
    "        # Analizza risultati\n",
    "        for r in results:\n",
    "            if r.boxes is not None:\n",
    "                print(f\"\\n🔍 Predizioni per {image_path}:\")\n",
    "                print(f\"  • Numero di persone rilevate: {len(r.boxes)}\")\n",
    "                \n",
    "                for box in r.boxes:\n",
    "                    class_id = int(box.cls)\n",
    "                    confidence = float(box.conf)\n",
    "                    class_name = self.class_names[class_id]\n",
    "                    \n",
    "                    print(f\"  • {class_name}: {confidence:.2%}\")\n",
    "                    \n",
    "                    # Analisi posizione (per debugging)\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "                    aspect_ratio = width / height if height > 0 else 0\n",
    "                    \n",
    "                    print(f\"    - Posizione: ({int(x1)}, {int(y1)}) -> ({int(x2)}, {int(y2)})\")\n",
    "                    print(f\"    - Dimensioni: {int(width)}x{int(height)}\")\n",
    "                    print(f\"    - Aspect ratio: {aspect_ratio:.2f}\")\n",
    "            else:\n",
    "                print(f\"\\n❌ Nessuna persona rilevata in {image_path}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def create_confusion_matrix_advanced(self, model_path='best_fall_detection_yolo11.pt'):\n",
    "        \"\"\"Crea confusion matrix dettagliata per il test set\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CONFUSION MATRIX AVANZATA\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        model = YOLO(model_path)\n",
    "        \n",
    "        # Raccogli predizioni e ground truth\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        confidences = []\n",
    "        \n",
    "        test_images = self.dataset_path / 'images' / 'test'\n",
    "        test_labels = self.dataset_path / 'labels' / 'test'\n",
    "        \n",
    "        if test_images.exists() and test_labels.exists():\n",
    "            for img_file in test_images.glob('*.jpg'):\n",
    "                label_file = test_labels / (img_file.stem + '.txt')\n",
    "                \n",
    "                # Ground truth\n",
    "                true_classes = []\n",
    "                if label_file.exists():\n",
    "                    with open(label_file, 'r') as f:\n",
    "                        for line in f.readlines():\n",
    "                            if line.strip():\n",
    "                                class_id = int(line.split()[0])\n",
    "                                true_classes.append(class_id)\n",
    "                \n",
    "                # Predizioni\n",
    "                results = model.predict(source=str(img_file), conf=0.25, verbose=False)\n",
    "                \n",
    "                pred_classes = []\n",
    "                for r in results:\n",
    "                    if r.boxes is not None:\n",
    "                        for box in r.boxes:\n",
    "                            pred_classes.append(int(box.cls))\n",
    "                            confidences.append(float(box.conf))\n",
    "                \n",
    "                # Match predizioni con ground truth (semplificato per demo)\n",
    "                if true_classes and pred_classes:\n",
    "                    y_true.append(true_classes[0])\n",
    "                    y_pred.append(pred_classes[0])\n",
    "                elif true_classes and not pred_classes:\n",
    "                    y_true.append(true_classes[0])\n",
    "                    y_pred.append(-1)  # Non rilevato\n",
    "        \n",
    "        # Crea confusion matrix\n",
    "        if y_true and y_pred:\n",
    "            # Rimuovi non rilevati per CM standard\n",
    "            valid_idx = [i for i, pred in enumerate(y_pred) if pred != -1]\n",
    "            y_true_valid = [y_true[i] for i in valid_idx]\n",
    "            y_pred_valid = [y_pred[i] for i in valid_idx]\n",
    "            \n",
    "            cm = confusion_matrix(y_true_valid, y_pred_valid)\n",
    "            \n",
    "            # Visualizza\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                       xticklabels=['not_fallen', 'fallen'],\n",
    "                       yticklabels=['not_fallen', 'fallen'])\n",
    "            plt.title('Confusion Matrix - YOLO11 Fall Detection', fontsize=14, fontweight='bold')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            \n",
    "            # Aggiungi metriche\n",
    "            for i in range(2):\n",
    "                precision = cm[i, i] / np.sum(cm[:, i]) if np.sum(cm[:, i]) > 0 else 0\n",
    "                recall = cm[i, i] / np.sum(cm[i, :]) if np.sum(cm[i, :]) > 0 else 0\n",
    "                f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "                \n",
    "                plt.text(-0.5, i + 0.5, f'Recall: {recall:.2f}\\nF1: {f1:.2f}', \n",
    "                        ha='right', va='center', fontsize=10)\n",
    "                plt.text(i + 0.5, 2.3, f'Prec: {precision:.2f}', \n",
    "                        ha='center', va='top', fontsize=10)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Report dettagliato\n",
    "            print(\"\\n📊 REPORT DETTAGLIATO:\")\n",
    "            print(classification_report(y_true_valid, y_pred_valid,\n",
    "                                      target_names=['not_fallen', 'fallen'],\n",
    "                                      digits=3))\n",
    "            \n",
    "            # Statistiche aggiuntive\n",
    "            print(f\"\\n📈 STATISTICHE AGGIUNTIVE:\")\n",
    "            print(f\"  • Immagini testate: {len(y_true)}\")\n",
    "            print(f\"  • Rilevamenti mancati: {y_pred.count(-1)}\")\n",
    "            if confidences:\n",
    "                print(f\"  • Confidence media: {np.mean(confidences):.3f}\")\n",
    "                print(f\"  • Confidence min/max: {np.min(confidences):.3f} / {np.max(confidences):.3f}\")\n",
    "\n",
    "\n",
    "\"\"\"# Esempio di utilizzo\n",
    "if __name__ == \"__main__\":\n",
    "    # ====================================\n",
    "    # CONFIGURAZIONE\n",
    "    # ====================================\n",
    "    \n",
    "    # Path al dataset in formato YOLO\n",
    "    # Struttura richiesta:\n",
    "    # dataset/\n",
    "    #   ├── train/\n",
    "    #   │   ├── images/\n",
    "    #   │   └── labels/\n",
    "    #   ├── val/\n",
    "    #   │   ├── images/\n",
    "    #   │   └── labels/\n",
    "    #   ├── test/\n",
    "    #   │   ├── images/\n",
    "    #   │   └── labels/\n",
    "    #   └── data.yaml\n",
    "    \n",
    "    DATASET_PATH = \"path/to/your/yolo/dataset\"  # Modifica con il tuo path\n",
    "    \n",
    "    # Verifica esistenza dataset\n",
    "    if not os.path.exists(DATASET_PATH):\n",
    "        print(\"❌ ERRORE: Dataset non trovato!\")\n",
    "        print(f\"Path specificato: {DATASET_PATH}\")\n",
    "        print(\"\\nAssicurati che il dataset sia in formato YOLO con questa struttura:\")\n",
    "        print(\"dataset/\")\n",
    "        print(\"  ├── train/\")\n",
    "        print(\"  │   ├── images/\")\n",
    "        print(\"  │   └── labels/\")\n",
    "        print(\"  ├── val/\")\n",
    "        print(\"  └── test/\")\n",
    "    else:\n",
    "        print(\"✅ Dataset trovato!\")\n",
    "        \n",
    "        # Inizializza trainer\n",
    "        trainer = YOLOFallDetectionTrainer(\n",
    "            dataset_path=DATASET_PATH,\n",
    "            model_name='yolo11n.pt',  # Usa yolo11n per CPU (più veloce)\n",
    "            img_size=640  # Dimensione standard YOLO\n",
    "        )\n",
    "        \n",
    "        # 1. Analisi del dataset\n",
    "        print(\"\\n🔍 FASE 1: Analisi Dataset\")\n",
    "        trainer.analyze_dataset()\n",
    "        \n",
    "        # 2. Creazione dataset augmentato (opzionale ma consigliato)\n",
    "        print(\"\\n🔄 FASE 2: Data Augmentation\")\n",
    "        response = input(\"\\nVuoi creare un dataset augmentato? (s/n): \")\n",
    "        if response.lower() == 's':\n",
    "            trainer.create_augmented_dataset(augmentation_factor=3)\n",
    "        \n",
    "        # 3. Training\n",
    "        print(\"\\n🚀 FASE 3: Training\")\n",
    "        response = input(\"\\nVuoi avviare il training? (s/n): \")\n",
    "        if response.lower() == 's':\n",
    "            model, results, metrics = trainer.train_model(\n",
    "                epochs=100,  # Riduci se vuoi test più veloci\n",
    "                patience=20,\n",
    "                batch_size=16  # Riduci se hai poca RAM\n",
    "            )\n",
    "        \n",
    "        # 4. Test e valutazione\n",
    "        print(\"\\n📊 FASE 4: Test e Valutazione\")\n",
    "        if os.path.exists('best_fall_detection_yolo11.pt'):\n",
    "            trainer.test_model()\n",
    "            trainer.create_confusion_matrix_advanced()\n",
    "        \n",
    "        # 5. Esempio predizione singola immagine\n",
    "        print(\"\\n🖼️ FASE 5: Test Predizione\")\n",
    "        test_image = input(\"\\nInserisci il path di un'immagine di test (o premi Enter per saltare): \")\n",
    "        if test_image and os.path.exists(test_image):\n",
    "            trainer.predict_image(test_image)\n",
    "    \n",
    "    print(\"\\n✅ Processo completato!\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72465bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/Users/andreavisi/Desktop/PYTHON/Sistemi operativi Dedicati 2025/PROGETTO/Eyes_on_falls_YOLO/Datasets/balanced_yolo_dataset\"\n",
    "\n",
    "# Verifica esistenza dataset\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(\"❌ ERRORE: Dataset non trovato!\")\n",
    "    print(f\"Path specificato: {DATASET_PATH}\")\n",
    "    print(\"\\nAssicurati che il dataset sia in formato YOLO con questa struttura:\")\n",
    "    print(\"balanced_yolo_dataset/\")\n",
    "    print(\"  ├── images/\")\n",
    "    print(\"  │   ├── train/\")\n",
    "    print(\"  │   ├── val/\")\n",
    "    print(\"  │   └── test/\")\n",
    "    print(\"  └── labels/\")\n",
    "    print(\"      ├── train/\")\n",
    "    print(\"      ├── val/\")\n",
    "    print(\"      └── test/\")\n",
    "else:\n",
    "    print(\"✅ Dataset trovato!\")\n",
    "    print(f\"📁 Directory: {DATASET_PATH}\")\n",
    "    \n",
    "    # Verifica struttura directory\n",
    "    dataset_path = Path(DATASET_PATH)\n",
    "    images_dir = dataset_path / 'images'\n",
    "    labels_dir = dataset_path / 'labels'\n",
    "    \n",
    "    if images_dir.exists() and labels_dir.exists():\n",
    "        print(\"✅ Struttura dataset corretta!\")\n",
    "        \n",
    "        # Verifica sottocartelle\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            img_split = images_dir / split\n",
    "            lbl_split = labels_dir / split\n",
    "            print(f\"\\n{split.upper()}:\")\n",
    "            print(f\"  • Images: {'✅' if img_split.exists() else '❌'} ({len(list(img_split.glob('*.jpg'))) if img_split.exists() else 0} files)\")\n",
    "            print(f\"  • Labels: {'✅' if lbl_split.exists() else '❌'} ({len(list(lbl_split.glob('*.txt'))) if lbl_split.exists() else 0} files)\")\n",
    "        \n",
    "        # Inizializza trainer\n",
    "        trainer = YOLOFallDetectionTrainer(\n",
    "            dataset_path=DATASET_PATH,\n",
    "            model_name='yolo11n.pt',  # Usa yolo11n per CPU (più veloce)\n",
    "            img_size=640  # Dimensione standard YOLO\n",
    "        )\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print(\"❌ ERRORE: Struttura dataset non corretta!\")\n",
    "        print(\"Assicurati di avere le cartelle 'images' e 'labels' con sottocartelle train/val/test\")\n",
    "\n",
    "print(\"\\n✅ Processo completato!\")\n",
    "\n",
    "# ====================================\n",
    "# NOTE IMPORTANTI PER L'USO\n",
    "# ====================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📝 NOTE IMPORTANTI:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. STRUTTURA DATASET:\")\n",
    "print(\"   Il tuo dataset DEVE avere questa struttura:\")\n",
    "print(\"   balanced_yolo_dataset/\")\n",
    "print(\"     ├── images/\")\n",
    "print(\"     │   ├── train/ (immagini .jpg)\")\n",
    "print(\"     │   ├── val/   (immagini .jpg)\")\n",
    "print(\"     │   └── test/  (immagini .jpg)\")\n",
    "print(\"     └── labels/\")\n",
    "print(\"         ├── train/ (file .txt)\")\n",
    "print(\"         ├── val/   (file .txt)\")\n",
    "print(\"         └── test/  (file .txt)\")\n",
    "print(\"\\n2. FORMATO ANNOTAZIONI:\")\n",
    "print(\"   Ogni file .txt deve contenere:\")\n",
    "print(\"   <class_id> <x_center> <y_center> <width> <height>\")\n",
    "print(\"   dove: 0 = not_fallen, 1 = fallen\")\n",
    "print(\"\\n3. OTTIMIZZAZIONI CPU:\")\n",
    "print(\"   - Usa YOLOv11n (nano) per velocità\")\n",
    "print(\"   - Batch size 16 (riduci se hai poca RAM)\")\n",
    "print(\"   - Cache attivata per velocizzare\")\n",
    "print(\"\\n4. DATA AUGMENTATION:\")\n",
    "print(\"   - Focus su occlusioni e variazioni luminosità\")\n",
    "print(\"   - Fattore 3x consigliato per dataset piccoli\")\n",
    "print(\"   - Aumenta se hai <1000 immagini per classe\")\n",
    "# ===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🔍 FASE 1: Analisi Dataset\")\n",
    "trainer.analyze_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aac367",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🔄 FASE 2: Data Augmentation\")\n",
    "response = input(\"\\nVuoi creare un dataset augmentato? (s/n): \")\n",
    "if response.lower() == 's':\n",
    "    trainer.create_augmented_dataset(augmentation_factor=3, show_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e89ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/Users/andreavisi/Desktop/PYTHON/Sistemi operativi Dedicati 2025/PROGETTO/Eyes_on_falls_YOLO/Datasets/augmented_yolo_dataset\"\n",
    "\n",
    "# Verifica esistenza dataset\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(\"❌ ERRORE: Dataset non trovato!\")\n",
    "    print(f\"Path specificato: {DATASET_PATH}\")\n",
    "    print(\"\\nAssicurati che il dataset sia in formato YOLO con questa struttura:\")\n",
    "    print(\"balanced_yolo_dataset/\")\n",
    "    print(\"  ├── images/\")\n",
    "    print(\"  │   ├── train/\")\n",
    "    print(\"  │   ├── val/\")\n",
    "    print(\"  │   └── test/\")\n",
    "    print(\"  └── labels/\")\n",
    "    print(\"      ├── train/\")\n",
    "    print(\"      ├── val/\")\n",
    "    print(\"      └── test/\")\n",
    "else:\n",
    "    print(\"✅ Dataset trovato!\")\n",
    "    print(f\"📁 Directory: {DATASET_PATH}\")\n",
    "    \n",
    "    # Verifica struttura directory\n",
    "    dataset_path = Path(DATASET_PATH)\n",
    "    images_dir = dataset_path / 'images'\n",
    "    labels_dir = dataset_path / 'labels'\n",
    "    \n",
    "    if images_dir.exists() and labels_dir.exists():\n",
    "        print(\"✅ Struttura dataset corretta!\")\n",
    "        \n",
    "        # Verifica sottocartelle\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            img_split = images_dir / split\n",
    "            lbl_split = labels_dir / split\n",
    "            print(f\"\\n{split.upper()}:\")\n",
    "            print(f\"  • Images: {'✅' if img_split.exists() else '❌'} ({len(list(img_split.glob('*.jpg'))) if img_split.exists() else 0} files)\")\n",
    "            print(f\"  • Labels: {'✅' if lbl_split.exists() else '❌'} ({len(list(lbl_split.glob('*.txt'))) if lbl_split.exists() else 0} files)\")\n",
    "        \n",
    "        # Inizializza trainer\n",
    "        trainer = YOLOFallDetectionTrainer(\n",
    "            dataset_path=DATASET_PATH,\n",
    "            model_name='yolo11n.pt',  # Usa yolo11n per CPU (più veloce)\n",
    "            img_size=640  # Dimensione standard YOLO\n",
    "        )\n",
    "        \n",
    "\n",
    "    else:\n",
    "        print(\"❌ ERRORE: Struttura dataset non corretta!\")\n",
    "        print(\"Assicurati di avere le cartelle 'images' e 'labels' con sottocartelle train/val/test\")\n",
    "\n",
    "print(\"\\n✅ Processo completato!\")\n",
    "\n",
    "# ====================================\n",
    "# NOTE IMPORTANTI PER L'USO\n",
    "# ====================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📝 NOTE IMPORTANTI:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. STRUTTURA DATASET:\")\n",
    "print(\"   Il tuo dataset DEVE avere questa struttura:\")\n",
    "print(\"   balanced_yolo_dataset/\")\n",
    "print(\"     ├── images/\")\n",
    "print(\"     │   ├── train/ (immagini .jpg)\")\n",
    "print(\"     │   ├── val/   (immagini .jpg)\")\n",
    "print(\"     │   └── test/  (immagini .jpg)\")\n",
    "print(\"     └── labels/\")\n",
    "print(\"         ├── train/ (file .txt)\")\n",
    "print(\"         ├── val/   (file .txt)\")\n",
    "print(\"         └── test/  (file .txt)\")\n",
    "print(\"\\n2. FORMATO ANNOTAZIONI:\")\n",
    "print(\"   Ogni file .txt deve contenere:\")\n",
    "print(\"   <class_id> <x_center> <y_center> <width> <height>\")\n",
    "print(\"   dove: 0 = not_fallen, 1 = fallen\")\n",
    "print(\"\\n3. OTTIMIZZAZIONI CPU:\")\n",
    "print(\"   - Usa YOLOv11n (nano) per velocità\")\n",
    "print(\"   - Batch size 16 (riduci se hai poca RAM)\")\n",
    "print(\"   - Cache attivata per velocizzare\")\n",
    "print(\"\\n4. DATA AUGMENTATION:\")\n",
    "print(\"   - Focus su occlusioni e variazioni luminosità\")\n",
    "print(\"   - Fattore 3x consigliato per dataset piccoli\")\n",
    "print(\"   - Aumenta se hai <1000 immagini per classe\")\n",
    "# ===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🚀 FASE 3: Training\")\n",
    "response = input(\"\\nVuoi avviare il training? (s/n): \")\n",
    "if response.lower() == 's':\n",
    "    model, results, metrics = trainer.train_model(\n",
    "        epochs=100,  \n",
    "        patience=15,\n",
    "        batch_size=4  # Riduci se hai poca RAM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📊 FASE 4: Test e Valutazione\")\n",
    "if os.path.exists('best_fall_detection_yolo11.pt'):\n",
    "    trainer.test_model()\n",
    "    trainer.create_confusion_matrix_advanced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🖼️ FASE 5: Test Predizione\")\n",
    "test_image = input(\"\\nInserisci il path di un'immagine di test (o premi Enter per saltare): \")\n",
    "if test_image and os.path.exists(test_image):\n",
    "    trainer.predict_image(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c297522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "def monitor_video_stream(model, source=0):\n",
    "    \"\"\"Monitora uno stream video per rilevare cadute.\"\"\"\n",
    "    import cv2\n",
    "    \n",
    "    # Apri stream video\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        # Leggi frame\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        # Converti colori per YOLOv11\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Predici\n",
    "        results = model.predict(frame_rgb, conf=0.5)\n",
    "        \n",
    "        # Processa risultati\n",
    "        annotated_frame = results[0].plot()\n",
    "        \n",
    "        # Converti colori per visualizzazione\n",
    "        annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Mostra\n",
    "        cv2.imshow(\"YOLOv11 Fallen Person Detection\", annotated_frame)\n",
    "        \n",
    "        # Premi 'q' per uscire\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Rilascia risorse\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "model_path = \"/Users/andreavisi/Desktop/PYTHON/Sistemi operativi Dedicati 2025/PROGETTO/Eyes_on_falls_YOLO/3. fallen_people_detection/best_fall_detection_yolo11.pt\"\n",
    "model = YOLO(model_path)\n",
    "#model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Avvia monitoraggio (webcam)\n",
    "monitor_video_stream(model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df9f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
